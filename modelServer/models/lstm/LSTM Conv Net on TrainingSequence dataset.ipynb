{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras ConvLSTM2D network\n",
    "\n",
    "Use a network made of convolutional LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, None, None, None,  59200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, None, None, None,  115360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, None, None, None,  115360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, None, None, None,  115360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, None, None, None,  1081      \n",
      "=================================================================\n",
      "Total params: 407,001\n",
      "Trainable params: 406,681\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#kernel_size = (3,3)\n",
    "#img_input = Input(shape=(None,None,None,1,))\n",
    "#x = ConvLSTM2D(32, kernel_size, activation='relu', padding='same', return_sequences=True)(img_input)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = ConvLSTM2D(32, kernel_size, activation='relu', padding='same', return_sequences=True)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = ConvLSTM2D(32, kernel_size, activation='relu', padding='same', return_sequences=True)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = ConvLSTM2D(32, kernel_size, activation='relu', padding='same', return_sequences=True)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = ConvLSTM2D(1, kernel_size, activation='softmax', padding='same', return_sequences=False)(x)\n",
    "#model = Model(inputs=img_input, outputs=x)\n",
    "#model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy')\n",
    "#model.summary()\n",
    "\n",
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, None, None, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "\n",
    "model = seq\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model/ConvLSTM-TrainingSequence.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data\n",
    "\n",
    "Full games are represented as image sequences (\"movies\"). \n",
    "\n",
    "The input data is the full game without the last state where all lines are filled in. \n",
    "The output data only shows the newly added line in each frame - all pixels are black except for the new line in white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequenceDataset = np.load('TrainingSequence-5x4.npz')\n",
    "sequenceDataset = np.load('TrainingSequence-3x4.npz')\n",
    "x_train = sequenceDataset['input_seq']\n",
    "y_train = sequenceDataset['target_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 31, 11, 9)\n",
      "(10000, 31, 11, 9)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215 255 215   0]\n",
      " [  0 255   0   0   0 255  65 255   0]\n",
      " [  0 215 255 215 255 215 255 215   0]\n",
      " [  0 255 150 255   0   0   0 255   0]\n",
      " [  0 215 255 215   0 215   0 215   0]\n",
      " [  0 255  65 255   0   0   0 255   0]\n",
      " [  0 215 255 215 255 215 255 215   0]\n",
      " [  0 255   0 255 150 255 150 255   0]\n",
      " [  0 215   0 215 255 215 255 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "[[  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 255   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0,23])\n",
    "print(\"-\"*80)\n",
    "print(y_train[0,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val = 255\n"
     ]
    }
   ],
   "source": [
    "val = np.sum(y_train[0,23])\n",
    "print(\"val = %d\" % val)\n",
    "assert(abs(val) == 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(K.floatx())\n",
    "y_train = y_train.astype(K.floatx())\n",
    "x_train /= 255\n",
    "y_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.84 1.   0.84 1.   0.84 1.   0.84 0.  ]\n",
      " [0.   1.   0.   0.   0.   1.   0.59 1.   0.  ]\n",
      " [0.   0.84 0.   0.84 0.   0.84 1.   0.84 0.  ]\n",
      " [0.   1.   0.   0.   0.   1.   0.59 1.   0.  ]\n",
      " [0.   0.84 1.   0.84 0.   0.84 1.   0.84 0.  ]\n",
      " [0.   1.   0.   0.   0.   1.   0.59 1.   0.  ]\n",
      " [0.   0.84 0.   0.84 1.   0.84 1.   0.84 0.  ]\n",
      " [0.   1.   0.   1.   0.25 1.   0.59 1.   0.  ]\n",
      " [0.   0.84 0.   0.84 1.   0.84 1.   0.84 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "\n",
    "exampleGameIdx = 42\n",
    "exampleGameFrame = 23\n",
    "\n",
    "print(x_train[exampleGameIdx,exampleGameFrame])\n",
    "print(y_train[exampleGameIdx,exampleGameFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 31, 11, 9, 1)\n",
      "(10000, 31, 11, 9, 1)\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.84 1.   0.84 1.   0.84 1.   0.84 1.   0.84 0.  ]\n",
      " [0.   1.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.84 0.   0.84 0.   0.84 0.   0.84 1.   0.84 0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   1.   0.25 1.   0.  ]\n",
      " [0.   0.84 1.   0.84 1.   0.84 1.   0.84 1.   0.84 0.  ]\n",
      " [0.   1.   0.59 1.   0.59 1.   0.59 1.   0.59 1.   0.  ]\n",
      " [0.   0.84 1.   0.84 1.   0.84 1.   0.84 1.   0.84 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "channel_shape = x_train.shape + (1,)\n",
    "x_train = x_train.reshape(channel_shape)\n",
    "\n",
    "# Convert to categorical:\n",
    "#cat_shape = y_train.shape + (2,)\n",
    "#y_train = to_categorical(y_train)\n",
    "#y_train = y_train.reshape(cat_shape)\n",
    "\n",
    "# Don't convert to categorical:\n",
    "cat_shape = y_train.shape + (1,)\n",
    "y_train = y_train.reshape(cat_shape)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(np.transpose(x_train[exampleGameIdx,exampleGameFrame,:,:,0]))\n",
    "print(np.transpose(y_train[exampleGameIdx,exampleGameFrame,:,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "9500/9500 [==============================] - 308s - loss: 3.3985e-06 - val_loss: 2.6885e-06\n",
      "Epoch 2/20\n",
      "9500/9500 [==============================] - 304s - loss: 2.5038e-06 - val_loss: 2.3002e-06\n",
      "Epoch 3/20\n",
      "9500/9500 [==============================] - 304s - loss: 2.1856e-06 - val_loss: 2.0362e-06\n",
      "Epoch 4/20\n",
      "9500/9500 [==============================] - 305s - loss: 1.9609e-06 - val_loss: 1.8456e-06\n",
      "Epoch 5/20\n",
      "9500/9500 [==============================] - 304s - loss: 1.7875e-06 - val_loss: 1.6922e-06\n",
      "Epoch 6/20\n",
      "7780/9500 [=======================>......] - ETA: 54s - loss: 1.6569e-06"
     ]
    }
   ],
   "source": [
    "#model.fit(x_train[0:8:1,:,:,:,:], y_train[0:8:1,:,:,:,:], epochs=50, batch_size=16)\n",
    "model.fit(x_train, y_train, batch_size=10,\n",
    "        epochs=20, validation_split=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 11, 13, 1)\n",
      "(11, 13)\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.68 0.   0.   0.   0.07 0.   0.01 0.   0.19 0.   0.  ]\n",
      " [0.   0.04 0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.02 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.02 0.   0.   0.   0.   0.   0.01 0.   0.   0.  ]\n",
      " [0.   0.   0.01 0.   0.06 0.   0.31 0.   0.04 0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.84 0.   0.84 1.   0.84 0.   0.84 0.   0.84 0.   0.84 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.  ]\n",
      " [0.   0.84 0.   0.84 1.   0.84 1.   0.84 1.   0.84 1.   0.84 0.  ]\n",
      " [0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   1.   0.  ]\n",
      " [0.   0.84 1.   0.84 0.   0.84 0.   0.84 0.   0.84 0.   0.84 0.  ]\n",
      " [0.   1.   0.   0.   0.   1.   0.   1.   0.   1.   0.   1.   0.  ]\n",
      " [0.   0.84 0.   0.84 1.   0.84 0.   0.84 0.   0.84 0.   0.84 0.  ]\n",
      " [0.   1.   0.   0.   0.   1.   0.   1.   0.   0.   0.   1.   0.  ]\n",
      " [0.   0.84 0.   0.84 0.   0.84 0.   0.84 1.   0.84 0.   0.84 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "(11, 26)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABuCAIAAABk51xTAAAByklEQVR4nO3du00DQRgA4eMRQQBl\n4JBKkCgUiUoIz2VAABGvDmaRlsNjMV+6Wq+P4YLTj82yJEmSJEmSnznh5RVXdw+4955Wb/CV93zu\nNZ77jHvxitcv3HuLe59wLy0up7iaP1IGhTIolEGhDAplUCiDQhkUyqAweIpeLnD17ffeiAT/PPAZ\nGxcHL9zdoFAGhTIolEGhDAplUCiDQhkUyqBwzssrPifzfJXn2DOz6A334qPwzLmsu0GhDAplUCiD\nQhkUyqBQBoUyKJRBYTSLPsPVD1qcmc0ezIGut7tBoQwKZVAog0IZFMqgUAaFMiiUQWE0i8bnxu1m\ns4PPY2+3F693h7+0+098adTdoFAGhTIolEGhDAplUCiDQhkUyqAwGAkfap48c+4x7u1uUCiDQhkU\nyqBQBoUyKJRBoQwKZVAYzKK3mydPzbHx7673OE9mM9fb56KPXhkUyqBQBoUyKJRBoQwKZVAog8KW\ns2h+Qn/f6typ99x3dP9nZVAog0IZFMqgUAaFMiiUQaEMCnOzaIy44nPy7grPfcFz73DvI61+XeLe\nV1rl/zXN3+/NuhsUyqBQBoUyKJRBoQwKZVAog0IZkiRJkiTJUfkGHQ8+wh4g/pEAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=130x110 at 0x7F71A8255650>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.randrange(x_train.shape[0])\n",
    "exampleFrame = 20\n",
    "input_data = np.array([x_train[example,0:exampleFrame,::,::,::]])\n",
    "prediction = model.predict(input_data)\n",
    "print(prediction.shape)\n",
    "prediction = prediction[0,-1, ::, ::, 0]\n",
    "print(prediction.shape)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "print(x_train[example,exampleFrame,::,::,0])\n",
    "\n",
    "# create image\n",
    "target_imgdata = x_train[example,exampleFrame,::,::,0] * 255\n",
    "target_imgdata = target_imgdata.astype(np.uint8)\n",
    "\n",
    "prediction_imgdata = prediction * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# merge image data in color channels\n",
    "tmp = np.zeros(prediction.shape, dtype=np.uint8)\n",
    "merged_imgdata = np.stack([target_imgdata, prediction_imgdata, tmp], axis=2)\n",
    "merged_imgdata_large = np.append(target_imgdata, prediction_imgdata, axis=1)\n",
    "print(merged_imgdata_large.shape)\n",
    "\n",
    "#create image\n",
    "img2 = Image.fromarray(merged_imgdata, 'RGB')\n",
    "img = Image.fromarray(merged_imgdata_large, 'P')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "img2 = img2.resize(size=(img2.size[0]*10, img2.size[1]*10))\n",
    "\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model/ConvLSTM-TrainingSequence.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAABuCAMAAAD2zp2wAAADAFBMVEUAAAABAQECAgIDAwMEBAQF\nBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUWFhYXFxcY\nGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJycoKCgpKSkqKior\nKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6Ojo7Ozs8PDw9PT0+\nPj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tMTExNTU1OTk5PT09QUFBR\nUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1eXl5fX19gYGBhYWFiYmJjY2Nk\nZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29wcHBxcXFycnJzc3N0dHR1dXV2dnZ3\nd3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGCgoKDg4OEhISFhYWGhoaHh4eIiIiJiYmK\nioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OUlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJyd\nnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWmpqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+w\nsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4uLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLD\nw8PExMTFxcXGxsbHx8fIyMjJycnKysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW\n1tbX19fY2NjZ2dna2trb29vc3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp\n6enq6urr6+vs7Ozt7e3u7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8\n/Pz9/f3+/v7////isF19AAABR0lEQVR4nO3bS07DMBSG0Z/HCAawFVbCTtkOywH1DmwJuWlCrChS\nzze8dV5nZKVKIkmSJK3suzWa/bSW122fjfpqLa97b/XZQ6vPPlrL54Nw+6YhQIAAAcKfGQQId4Vw\nRJ1y9OtLa87VRhwnCEIgVBACoYIQCBWEQKhOj7B927xnNucxpwchECoIgVBBCIQKQiBUEK7Ub/+I\n8z215lxt0vkgBEIFIRAqCIFQQQiE6u4Q1m5zZ8+O6LF1YyGEQKggBEIFIRAqCIFQQcj6LfJo3Z7Z\nqYIQCBWEQKggBEIFIRAqCDnX5z9rm/1qFsIlCIFQQQiECkIgVBACoZq9bd5zjd5za+0RvX98/gNh\nww1CuLIOws5jl4MQCBWEQKgg5HCEOdvh/ph7ts2jv9LfWn322eqz11afreaAAAECBAgQIECAIEmS\nJG3rF7RPM0PAcMxGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=P size=260x110 at 0x7F70ED7CBED0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
