{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras ConvLSTM2D network\n",
    "\n",
    "Use a network made of convolutional LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import SequenceLineFilterLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = 'model/lstmcategorical.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7390a3f3d6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model/LSTMCategorical.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;31m# instantiate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-4rPeHA-build/h5py/_objects.c:2684)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-4rPeHA-build/h5py/_objects.c:2642)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/tmp/pip-4rPeHA-build/h5py/h5f.c:1930)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = 'model/lstmcategorical.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model/LSTMCategorical.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data\n",
    "\n",
    "Full games are represented as image sequences (\"movies\"). The network has to predict the next frame of an unfinished sequence.\n",
    "\n",
    "The input data is the full game without the last state where all lines are filled in. The output data is the full game without the very first state where no lines are drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 49, 11, 13)\n"
     ]
    }
   ],
   "source": [
    "sequenceDataset = np.load('sequence5x4.npz')\n",
    "games = sequenceDataset['games']\n",
    "print(games.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, None, None, None,  164160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, None, None, None,  320160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, None, None, None,  320160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, None, None, None,  320160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)  (None, None, None, None,  320160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, None, None,  160       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, None, None, None,  5001      \n",
      "_________________________________________________________________\n",
      "sequence_line_filter_layer_1 (None, None, None)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, None)        0         \n",
      "=================================================================\n",
      "Total params: 1,450,601\n",
      "Trainable params: 1,450,201\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(5, 5),\n",
    "                   input_shape=(None, None, None, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(5, 5),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(5, 5),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(5, 5),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(5, 5),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(5,5,5), padding='same'))\n",
    "\n",
    "seq.add(SequenceLineFilterLayer.SequenceLineFilterLayer(games.shape[-1], games.shape[-2], noShapeCheck=True))\n",
    "\n",
    "seq.add(Activation('softmax'))\n",
    "\n",
    "seq.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "\n",
    "model = seq\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 40)\n",
      "(None, None, None, None, 1)\n",
      "(None, None, None)\n",
      "(None, None, None)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def imgSizeToBoxes(x):\n",
    "    return (x-3)/2\n",
    "\n",
    "def lineFilterMatrixNP(imgWidth,imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=np.bool)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = 1\n",
    "    return mat\n",
    "\n",
    "lineFilterMatrixNP(13,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 48, 11, 13)\n",
      "(1000, 48, 49)\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "x_train = games[:,:-1,:,:]\n",
    "y_train = np.subtract(games[:,0:-1,:,:], games[:,1:,:,:])[:,:,lineFilterMatrixNP(x_train.shape[-1], x_train.shape[-2])]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_train[23,10])\n",
    "print(np.subtract(games[23,0:-1,:,:], games[23,1:,:,:])[10])\n",
    "\n",
    "x_train = x_train.astype(K.floatx())\n",
    "y_train = y_train.astype(K.floatx())\n",
    "#x_train /= 255\n",
    "#y_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 215.   0. 215.   0. 215.   0. 215.   0. 215.   0. 215.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0. 255.   0.   0.   0.]\n",
      " [  0. 215.   0. 215.   0. 215.   0. 215. 255. 215.   0. 215.   0.]\n",
      " [  0.   0.   0.   0.   0. 255.   0.   0.   0. 255.   0.   0.   0.]\n",
      " [  0. 215.   0. 215. 255. 215.   0. 215.   0. 215. 255. 215.   0.]\n",
      " [  0.   0.   0.   0.   0. 255.   0.   0.   0. 255.   0.   0.   0.]\n",
      " [  0. 215. 255. 215.   0. 215.   0. 215. 255. 215.   0. 215.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 215.   0. 215.   0. 215.   0. 215. 255. 215.   0. 215.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "\n",
    "exampleGameIdx = 23\n",
    "exampleGameFrame = 10\n",
    "\n",
    "print(x_train[exampleGameIdx,exampleGameFrame])\n",
    "print(y_train[exampleGameIdx,exampleGameFrame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 48, 11, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 855 samples, validate on 45 samples\n",
      "Epoch 1/20\n",
      "855/855 [==============================] - 122s 143ms/step - loss: 4.7729 - val_loss: 3.7560\n",
      "Epoch 2/20\n",
      "855/855 [==============================] - 119s 140ms/step - loss: 1.6678 - val_loss: 0.2126\n",
      "Epoch 3/20\n",
      "855/855 [==============================] - 119s 140ms/step - loss: 0.0037 - val_loss: 0.0298\n",
      "Epoch 4/20\n",
      "855/855 [==============================] - 119s 140ms/step - loss: 4.6381e-04 - val_loss: 0.0040\n",
      "Epoch 5/20\n",
      "855/855 [==============================] - 119s 140ms/step - loss: 1.0994e-04 - val_loss: 7.7366e-04\n",
      "Epoch 6/20\n",
      "855/855 [==============================] - 121s 141ms/step - loss: 3.3711e-05 - val_loss: 4.0657e-04\n",
      "Epoch 7/20\n",
      "855/855 [==============================] - 121s 141ms/step - loss: 1.8153e-05 - val_loss: 2.3299e-04\n",
      "Epoch 8/20\n",
      "855/855 [==============================] - 120s 141ms/step - loss: 1.2598e-05 - val_loss: 1.6577e-04\n",
      "Epoch 9/20\n",
      "855/855 [==============================] - 121s 142ms/step - loss: 9.7060e-06 - val_loss: 1.3483e-04\n",
      "Epoch 10/20\n",
      "855/855 [==============================] - 123s 144ms/step - loss: 7.8859e-06 - val_loss: 1.2568e-04\n",
      "Epoch 11/20\n",
      "855/855 [==============================] - 120s 140ms/step - loss: 6.6504e-06 - val_loss: 1.1471e-04\n",
      "Epoch 12/20\n",
      "855/855 [==============================] - 120s 140ms/step - loss: 5.7850e-06 - val_loss: 1.1082e-04\n",
      "Epoch 13/20\n",
      "855/855 [==============================] - 122s 142ms/step - loss: 5.0824e-06 - val_loss: 1.0453e-04\n",
      "Epoch 14/20\n",
      "855/855 [==============================] - 122s 142ms/step - loss: 4.5539e-06 - val_loss: 1.0200e-04\n",
      "Epoch 15/20\n",
      "855/855 [==============================] - 120s 141ms/step - loss: 4.0959e-06 - val_loss: 1.0037e-04\n",
      "Epoch 16/20\n",
      "855/855 [==============================] - 119s 140ms/step - loss: 3.7540e-06 - val_loss: 9.9880e-05\n",
      "Epoch 17/20\n",
      "855/855 [==============================] - 121s 142ms/step - loss: 3.4453e-06 - val_loss: 9.4819e-05\n",
      "Epoch 18/20\n",
      "855/855 [==============================] - 120s 140ms/step - loss: 3.1869e-06 - val_loss: 9.5317e-05\n",
      "Epoch 19/20\n",
      "855/855 [==============================] - 120s 140ms/step - loss: 2.9751e-06 - val_loss: 9.0377e-05\n",
      "Epoch 20/20\n",
      "855/855 [==============================] - 121s 142ms/step - loss: 2.7861e-06 - val_loss: 8.9803e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f78df2f50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(x_train[0:8:1,:,:,:,:], y_train[0:8:1,:,:,:,:], epochs=50, batch_size=16)\n",
    "model.fit(x_train[:900], y_train[:900], batch_size=10,\n",
    "        epochs=20, validation_split=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/LSTMCategorical.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesToDotsAndBoxesImage(lines, imgWidth, imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=lines.dtype)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = lines[idx]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 49)\n",
      "(49,)\n",
      "(11, 13)\n",
      "input:\n",
      "(1000, 48, 11, 13, 1)\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 215.   0. 215. 255. 215.   0. 215.   0. 215. 255. 215.   0.]\n",
      " [  0. 255.   0. 255.   0.   0.   0. 255.   0. 255. 150. 255.   0.]\n",
      " [  0. 215.   0. 215.   0. 215. 255. 215.   0. 215. 255. 215.   0.]\n",
      " [  0. 255.   0.   0.   0.   0.   0.   0.   0. 255. 150. 255.   0.]\n",
      " [  0. 215. 255. 215. 255. 215. 255. 215. 255. 215. 255. 215.   0.]\n",
      " [  0. 255.  65. 255.  65. 255.   0.   0.   0.   0.   0. 255.   0.]\n",
      " [  0. 215. 255. 215. 255. 215.   0. 215. 255. 215.   0. 215.   0.]\n",
      " [  0. 255. 150. 255. 150. 255.   0.   0.   0.   0.   0. 255.   0.]\n",
      " [  0. 215. 255. 215. 255. 215. 255. 215. 255. 215. 255. 215.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "prediction:\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.02 0.   0.   0.   0.05 0.   0.01 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.08 0.   0.07 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.04 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.02 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.02 0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.1  0.   0.58 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "(11, 13, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABuCAIAAABk51xTAAABxElEQVR4nO3dsU3DUBRG4ReUJgUF\nUppsgNdgGwqmocg2WcPeIE0kihRpELDBb6Srh4/J+dqri42OXJinhNYkSZIkSdLvbPJ4jNNhG3c/\n0/Q5/uQpX/cxXvcadx/i7lealu45TuNN6a+YAcEMCGZAMAOCGRDMgGAGBDMgzLxFfxeWK7sV/e75\nGKevhev6NCCYAcEMCGZAMAOCGRDMgGAGBDMgxNPkufPVto+7l7j7lIbjR5pWzoSzvJvfkyvX9WlA\nMAOCGRDMgGAGBDMgmAHBDAhmQOh4Ft12cXrLy8vwLPqumQHBDAhmQDADghkQzIBgBgQzIJTOovM7\n5xTfkyvnyUvtehb9z5kBwQwIZkAwA4IZEMyAYAYEMyCUzqJf4vTUbXfmpvNfBuJ3nlVUzu19GhDM\ngGAGBDMgmAHBDAhmQDADghkQSmfR+V233242893g8Tee4u4QX4Wn/Bod+TQgmAHBDAhmQDADghkQ\nzIBgBgQzIJTOoiufE+73GeN2iNNznL7H6Vsaeha9emZAMAOCGRDMgGAGBDMgmAHBDAil/xe9xs82\nL7Xr/4teATMgmAHBDAhmQDADghkQzIBgBkmSJEmStCo/xSE9FFe6GB0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=130x110 at 0x7F7FC8B44910>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.randrange(x_train.shape[0])\n",
    "exampleFrame = 32\n",
    "input_data = np.array([x_train[example,0:exampleFrame,::,::,::]])\n",
    "prediction = model.predict(input_data)\n",
    "print(prediction.shape)\n",
    "prediction = prediction[0, -1, ::]\n",
    "print(prediction.shape)\n",
    "prediction = linesToDotsAndBoxesImage(prediction, x_train.shape[-2], x_train.shape[-3])\n",
    "print(prediction.shape)\n",
    "\n",
    "print(\"input:\")\n",
    "print(x_train.shape)\n",
    "print(x_train[example,exampleFrame,::,::,0])\n",
    "\n",
    "print(\"prediction:\")\n",
    "print(prediction)\n",
    "\n",
    "# create image\n",
    "target_imgdata = x_train[example,exampleFrame,::,::,0]\n",
    "target_imgdata = target_imgdata.astype(np.uint8)\n",
    "\n",
    "prediction_imgdata = prediction * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# merge image data in color channels\n",
    "tmp = np.zeros(prediction.shape, dtype=np.uint8)\n",
    "merged_imgdata = np.stack([target_imgdata, prediction_imgdata, tmp], axis=2)\n",
    "merged_imgdata_large = np.append(target_imgdata, prediction_imgdata, axis=1)\n",
    "print(merged_imgdata.shape)\n",
    "\n",
    "#create image\n",
    "img = Image.fromarray(merged_imgdata, 'RGB')\n",
    "#img = Image.fromarray(merged_imgdata_large, 'P')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_imgdata = x_train[example,:,:,0] * 255\n",
    "target_imgdata = target_imgdata.astype(np.uint8)\n",
    "\n",
    "prediction_imgdata = prediction[0] * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# merge image data in color channels\n",
    "tmp = np.zeros((prediction[0].shape[0], prediction[0].shape[1]), dtype=np.uint8)\n",
    "merged_imgdata = np.stack([target_imgdata, prediction_imgdata[:,:,1], tmp], axis=2)\n",
    "\n",
    "#create image\n",
    "img = Image.fromarray(merged_imgdata, 'RGB')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
