{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('/home/ofenrohr/arbeit/master/code/alphaDots/stageOne/model/train-checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0   0   0 255   0   0   0   0   0 255   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0 255   0   0   0   0   0 255   0   0   0]\n",
      " [  0 215   0 215   0 215 255 215 255 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0 255   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215 255 215   0]\n",
      " [  0 255   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215 255 215 255 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 255   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "(1000000, 11, 13)\n",
      "(1000000, 11, 13)\n",
      "\n",
      "normalized data:\n",
      "[[[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  0.    0.84  0.    0.84  0.    0.84  1.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  0.    0.84  1.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  1.    0.84  0.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  0.    0.84  0.    0.84  1.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    1.    0.    0.    0.    1.    0.  ]\n",
      "  [ 0.    0.84  0.    0.84  1.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    1.    0.    1.    0.  ]\n",
      "  [ 0.    0.84  1.    0.84  0.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]]\n",
      "[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]\n",
      "(1000000, 11, 13, 1)\n",
      "(1000000, 11, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "firstTryDataset = np.load('stageOne5x4hard.npz')\n",
    "x_train = firstTryDataset['x_train']\n",
    "y_train = firstTryDataset['y_train']\n",
    "\n",
    "print(\"original data:\")\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print(\"\\nnormalized data:\")\n",
    "sp = x_train.shape\n",
    "x_train = x_train.reshape((sp[0],sp[1],sp[2],1))\n",
    "sp = y_train.shape\n",
    "y_train = y_train.reshape((sp[0],sp[1],sp[2],1))\n",
    "\n",
    "x_train = x_train.astype(K.floatx())\n",
    "y_train = y_train.astype(K.floatx())\n",
    "#x_train = np.true_divide(x_train,255.0)\n",
    "x_train /= 255\n",
    "y_train /= 255\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.transpose(x_train[0]))\n",
    "print(np.transpose(y_train[0]))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 11, 13, 2)\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "y_cat = to_categorical(y_train).reshape(y_train.shape[0], y_train.shape[1], y_train.shape[2], 2)\n",
    "print(y_cat.shape)\n",
    "print(y_cat[0,:,:,0])\n",
    "print(y_cat[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  84 100  84   0  84   0  84   0  84   0  84   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0]\n",
      " [  0  84   0  84 100  84 100  84 100  84   0  84   0]\n",
      " [  0   0   0 100   0   0   0 100   0 100   0   0   0]\n",
      " [  0  84   0  84   0  84   0  84   0  84   0  84   0]\n",
      " [  0   0   0   0   0 100   0 100   0   0   0   0   0]\n",
      " [  0  84   0  84   0  84   0  84 100  84   0  84   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  84 100  84 100  84 100  84   0  84   0  84   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "prediction: \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  1  0  1  0  2  0  0]\n",
      " [ 0  3  0  2  0  0  0  1  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  1  0  0  0 33  0  0  0  0]\n",
      " [ 0  2  0  2  0  0  0  0  0  1  0  2  0]\n",
      " [ 0  0  2  0  1  0  2  0  0  0  2  0  0]\n",
      " [ 0  2  0  1  0  1  0  1  0  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABuCAIAAABk51xTAAAB10lEQVR4nO3d203EMBQAUfNuhe2H\nMuknaYU3HYyRrLATac6vZYXd2XxYVwljJEmSJEmSv7nh5Q1Xn3F1x9XLA17347C997j3E/c+4t53\n3EuL4xZX80/KoFAGhTIolEGhDAplUCiDQhkUJqfo8YSrb4ft5Z/HN67iOXngOXnc4eoXLf7gVv6i\nuxsUyqBQBoUyKJRBoQwKZVAog0IZFPjEOTY8617waMh7J3NsPCdP9uI5ebIXz8n8eXc+RqPuBoUy\nKJRBoQwKZVAog0IZFMqgUAaF2Sx6Ya67MptdmWOvXHfpb16Yn3c3KJRBoQwKZVAog0IZFMqgUAaF\nMijMZtH8nDA+n7zj88l85ckMHH88PMceL7j3FffidTe8bs9Fn0AZFMqgUAaFMiiUQaEMCmVQKIPC\nbBaN79Ma+D6tU86TV56pXviuuhsUyqBQBoUyKJRBoQwKZVAog0IZFGazaH7vNL8r+7h58sIMnM/Y\n/Ez15PP2ju6zK4NCGRTKoFAGhTIolEGhDAplUDhyFr0y173Se7aX3g2+MHvvblAog0IZFMqgUAaF\nMiiUQaEMCmVQuNr/i77W3uP+5zN/V82iT6AMCmVQKINCGRTKoFAGhTIolCFJkiRJkpzKL+ssTZsR\nUhxoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=130x110 at 0x7EFD4DF3F2D0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.randrange(x_train.shape[0])\n",
    "\n",
    "input_data = np.array([x_train[example]])\n",
    "\n",
    "\n",
    "prediction = model.predict(input_data)\n",
    "\n",
    "# print input data\n",
    "input_data_print = x_train[example,:,:,0] * 100\n",
    "input_data_print = input_data_print.astype(np.uint8)\n",
    "print(\"input: \")\n",
    "print(input_data_print)\n",
    "\n",
    "# generate greyscale image data from input data\n",
    "target_imgdata = x_train[example,:,:,0] * 255\n",
    "target_imgdata = target_imgdata.astype(np.uint8)\n",
    "\n",
    "# print prediction\n",
    "prediction_data_print = prediction[0,:,:,1] * 100 \n",
    "prediction_data_print = prediction_data_print.astype(np.uint8)\n",
    "print(\"prediction: \")\n",
    "print(prediction_data_print)\n",
    "\n",
    "# generate greyscale image data from prediction data\n",
    "prediction_imgdata = prediction[0] * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# merge image data in color channels\n",
    "tmp = np.zeros((prediction[0].shape[0], prediction[0].shape[1]), dtype=np.uint8)\n",
    "merged_imgdata = np.stack([target_imgdata, prediction_imgdata[:,:,1], tmp], axis=2)\n",
    "\n",
    "#create image\n",
    "img = Image.fromarray(merged_imgdata, 'RGB')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Export the model\n",
    "Save the model. Export it with Keras's save method for use in the modelServer. The modelServer will provide the model's prediction function as a local Service for KSquares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = \"model/model-firstTry.h5\"\n",
    "model_json = model.save(model_path)\n",
    "img_path = \"model/model-firstTry.png\"\n",
    "plot_model(model, to_file=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: model/tensorflow/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model/tensorflow/saved_model.pb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'image': model.input}, \n",
    "    outputs={'scores': model.output})     \n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder('model/tensorflow')                                                                    \n",
    "builder.add_meta_graph_and_variables(                                                                                                        \n",
    "    sess=K.get_session(),                                                                                                                    \n",
    "    tags=[tf.saved_model.tag_constants.SERVING],                                                                                             \n",
    "    signature_def_map={                                                                                                                      \n",
    "        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:                                                                \n",
    "            signature                                                                                                                        \n",
    "    })                                                                                                                                       \n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
