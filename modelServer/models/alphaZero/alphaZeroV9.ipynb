{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero version 9\n",
    "\n",
    "This AlphaZero version starts from the weights of version 7 and is trained on augmented StageFour data. This is mostly about trying out data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from LineFilterLayer import LineFilterLayer\n",
    "from ValueLayer import ValueLayer\n",
    "from AugmentationSequence import AugmentationSequence\n",
    "\n",
    "modelPath = 'model/alphaZeroV9.h5'\n",
    "baseModelPath = 'model/alphaZeroV7.h5'\n",
    "\n",
    "datasetPath = 'StageFour-AlphaZeroV7-128-7x6-18:36-24_05_2018.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(K.image_data_format()) \n",
    "# expected output: channels_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotsAndBoxesToCategorical(inputData):\n",
    "    inp = np.copy(inputData)\n",
    "    inp[inp == 255] = 1 # Line - comes first so that target data only has two categories\n",
    "    inp[inp == 65] = 2 # Box A\n",
    "    inp[inp == 150] = 3 # Box B\n",
    "    inp[inp == 215] = 4 # Dot\n",
    "    cat = to_categorical(inp)\n",
    "    newShape = inp.shape + (cat.shape[-1],)\n",
    "    return cat.reshape(newShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgSizeToBoxes(x):\n",
    "    return (x-3)/2\n",
    "\n",
    "def lineFilterMatrixNP(imgWidth,imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=np.bool)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = 1\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRawPVDataset(datasetPath):\n",
    "    rawDataset = np.load(datasetPath)\n",
    "    \n",
    "    x_input = rawDataset['input']\n",
    "    y_policy = rawDataset['policy']\n",
    "    y_value = rawDataset['value']\n",
    "    \n",
    "    return (x_input, y_policy, y_value)\n",
    "\n",
    "def process_input(x_input):\n",
    "    return dotsAndBoxesToCategorical(x_input)\n",
    "\n",
    "def process_policy(y_policy):\n",
    "    y_policy = y_policy[:,lineFilterMatrixNP(y_policy.shape[-1], y_policy.shape[-2])]\n",
    "    y_policy /= 255\n",
    "    return y_policy\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "(x_input_raw, y_policy_raw, y_value_raw) = loadRawPVDataset(datasetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 15, 17)\n",
      "(128, 15, 17)\n",
      "(128, 1)\n",
      "raw input:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215 255 215 255 215 255 215 255 215   0 215 255 215   0]\n",
      " [  0 255   0 255 150 255  65 255  65 255   0   0   0 255  65 255   0]\n",
      " [  0 215   0 215 255 215 255 215 255 215   0 215 255 215 255 215   0]\n",
      " [  0 255   0 255 150 255  65 255  65 255   0 255   0   0   0 255   0]\n",
      " [  0 215   0 215 255 215 255 215 255 215   0 215   0 215   0 215   0]\n",
      " [  0 255   0 255 150 255  65 255  65 255   0 255   0 255   0   0   0]\n",
      " [  0 215   0 215 255 215 255 215 255 215   0 215   0 215 255 215   0]\n",
      " [  0 255   0 255   0   0   0   0   0   0   0 255   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215 255 215 255 215 255 215 255 215 255 215   0]\n",
      " [  0   0   0 255   0   0   0 255   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215 255 215 255 215   0 215   0 215 255 215 255 215 255 215   0]\n",
      " [  0 255  65 255  65 255   0 255   0   0   0 255 150 255 150 255   0]\n",
      " [  0 215 255 215 255 215   0 215 255 215   0 215 255 215 255 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "raw policy:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "raw value:\n",
      "[-0.29]\n"
     ]
    }
   ],
   "source": [
    "print(x_input_raw.shape)\n",
    "print(y_policy_raw.shape)\n",
    "print(y_value_raw.shape)\n",
    "print(\"raw input:\")\n",
    "print(x_input_raw[0])\n",
    "print(\"raw policy:\")\n",
    "print(y_policy_raw[0])\n",
    "print('raw value:')\n",
    "print(y_value_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LineFilterLayer with image size 17 x 15\n",
      "ValueLayer with image size 17 x 15\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 5 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_conv (Conv2D)             (None, None, None, 1 16128       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_relu (Activation)         (None, None, None, 1 0           input_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 1 512         input_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res1_conv1_128 (Conv2D)         (None, None, None, 1 409728      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res1_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res1_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res1_relu1 (Activation)         (None, None, None, 1 0           res1_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res1_conv2-128 (Conv2D)         (None, None, None, 1 409728      res1_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res1_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res1_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res1_add (Add)                  (None, None, None, 1 0           batch_normalization_1[0][0]      \n",
      "                                                                 res1_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res1_relu2 (Activation)         (None, None, None, 1 0           res1_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res2_conv1_128 (Conv2D)         (None, None, None, 1 409728      res1_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res2_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2_relu1 (Activation)         (None, None, None, 1 0           res2_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2_conv2-128 (Conv2D)         (None, None, None, 1 409728      res2_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res2_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2_add (Add)                  (None, None, None, 1 0           res1_relu2[0][0]                 \n",
      "                                                                 res2_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2_relu2 (Activation)         (None, None, None, 1 0           res2_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res3_conv1_128 (Conv2D)         (None, None, None, 1 409728      res2_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res3_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3_relu1 (Activation)         (None, None, None, 1 0           res3_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_conv2-128 (Conv2D)         (None, None, None, 1 409728      res3_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res3_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3_add (Add)                  (None, None, None, 1 0           res2_relu2[0][0]                 \n",
      "                                                                 res3_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_relu2 (Activation)         (None, None, None, 1 0           res3_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res4_conv1_128 (Conv2D)         (None, None, None, 1 409728      res3_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res4_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4_relu1 (Activation)         (None, None, None, 1 0           res4_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4_conv2-128 (Conv2D)         (None, None, None, 1 409728      res4_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res4_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4_add (Add)                  (None, None, None, 1 0           res3_relu2[0][0]                 \n",
      "                                                                 res4_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4_relu2 (Activation)         (None, None, None, 1 0           res4_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res5_conv1_128 (Conv2D)         (None, None, None, 1 409728      res4_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res5_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5_relu1 (Activation)         (None, None, None, 1 0           res5_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5_conv2-128 (Conv2D)         (None, None, None, 1 409728      res5_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res5_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5_add (Add)                  (None, None, None, 1 0           res4_relu2[0][0]                 \n",
      "                                                                 res5_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5_relu2 (Activation)         (None, None, None, 1 0           res5_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res6_conv1_128 (Conv2D)         (None, None, None, 1 409728      res5_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res6_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res6_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res6_relu1 (Activation)         (None, None, None, 1 0           res6_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res6_conv2-128 (Conv2D)         (None, None, None, 1 409728      res6_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res6_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res6_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res6_add (Add)                  (None, None, None, 1 0           res5_relu2[0][0]                 \n",
      "                                                                 res6_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res6_relu2 (Activation)         (None, None, None, 1 0           res6_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res7_conv1_128 (Conv2D)         (None, None, None, 1 409728      res6_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res7_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res7_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res7_relu1 (Activation)         (None, None, None, 1 0           res7_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res7_conv2-128 (Conv2D)         (None, None, None, 1 409728      res7_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res7_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res7_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res7_add (Add)                  (None, None, None, 1 0           res6_relu2[0][0]                 \n",
      "                                                                 res7_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res7_relu2 (Activation)         (None, None, None, 1 0           res7_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res8_conv1_128 (Conv2D)         (None, None, None, 1 409728      res7_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res8_batchnorm1 (BatchNormaliza (None, None, None, 1 512         res8_conv1_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res8_relu1 (Activation)         (None, None, None, 1 0           res8_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res8_conv2-128 (Conv2D)         (None, None, None, 1 409728      res8_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res8_batchnorm2 (BatchNormaliza (None, None, None, 1 512         res8_conv2-128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res8_add (Add)                  (None, None, None, 1 0           res7_relu2[0][0]                 \n",
      "                                                                 res8_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res8_relu2 (Activation)         (None, None, None, 1 0           res8_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy_conv (Conv2D)            (None, None, None, 1 3201        res8_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "value_conv (Conv2D)             (None, None, None, 1 3201        res8_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "line_filter_layer_1 (LineFilter (None, None)         0           policy_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "value_layer_1 (ValueLayer)      (None, 1)            0           value_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "policy (Activation)             (None, None)         0           line_filter_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "value (Activation)              (None, 1)            0           value_layer_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,586,882\n",
      "Trainable params: 6,582,530\n",
      "Non-trainable params: 4,352\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "imgWidth = x_input_raw.shape[-1]\n",
    "imgHeight = x_input_raw.shape[-2]\n",
    "# LineFilterLayer has to be set before loading the model\n",
    "LineFilterLayer.imgWidth = imgWidth\n",
    "LineFilterLayer.imgHeight = imgHeight\n",
    "# ValueLayer has to be set before loading the model\n",
    "ValueLayer.imgWidth = imgWidth\n",
    "ValueLayer.imgHeight = imgHeight\n",
    "\n",
    "model = load_model(baseModelPath,\n",
    "                   custom_objects={'LineFilterLayer':LineFilterLayer,\n",
    "                   'ValueLayer':ValueLayer})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "data_generator = AugmentationSequence(x_input_raw, y_policy_raw, y_value_raw, batch_size, process_input, process_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8/8 [==============================] - 4s 507ms/step - loss: 7.9643 - policy_loss: 7.6627 - value_loss: 0.2626\n",
      "Epoch 2/128\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 6.4436 - policy_loss: 6.1928 - value_loss: 0.2118\n",
      "Epoch 3/128\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 5.8185 - policy_loss: 5.5787 - value_loss: 0.2007\n",
      "Epoch 4/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 5.1229 - policy_loss: 4.8999 - value_loss: 0.1838\n",
      "Epoch 5/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 4.6413 - policy_loss: 4.4164 - value_loss: 0.1856\n",
      "Epoch 6/128\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 4.1071 - policy_loss: 3.8894 - value_loss: 0.1782\n",
      "Epoch 7/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 3.8342 - policy_loss: 3.6165 - value_loss: 0.1781\n",
      "Epoch 8/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 3.5639 - policy_loss: 3.3382 - value_loss: 0.1859\n",
      "Epoch 9/128\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 3.2926 - policy_loss: 3.0675 - value_loss: 0.1851\n",
      "Epoch 10/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.9966 - policy_loss: 2.7752 - value_loss: 0.1812\n",
      "Epoch 11/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.7192 - policy_loss: 2.5022 - value_loss: 0.1767\n",
      "Epoch 12/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.3744 - policy_loss: 2.1641 - value_loss: 0.1698\n",
      "Epoch 13/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.3752 - policy_loss: 2.1638 - value_loss: 0.1709\n",
      "Epoch 14/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.1702 - policy_loss: 1.9634 - value_loss: 0.1662\n",
      "Epoch 15/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.0340 - policy_loss: 1.8305 - value_loss: 0.1628\n",
      "Epoch 16/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 2.0701 - policy_loss: 1.8613 - value_loss: 0.1680\n",
      "Epoch 17/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.8708 - policy_loss: 1.6650 - value_loss: 0.1650\n",
      "Epoch 18/128\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.6751 - policy_loss: 1.4710 - value_loss: 0.1632\n",
      "Epoch 19/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.6004 - policy_loss: 1.3950 - value_loss: 0.1645\n",
      "Epoch 20/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.6681 - policy_loss: 1.4636 - value_loss: 0.1634\n",
      "Epoch 21/128\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.3969 - policy_loss: 1.2010 - value_loss: 0.1549\n",
      "Epoch 22/128\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 1.4554 - policy_loss: 1.2618 - value_loss: 0.1525\n",
      "Epoch 23/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.3635 - policy_loss: 1.1677 - value_loss: 0.1545\n",
      "Epoch 24/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.3543 - policy_loss: 1.1591 - value_loss: 0.1539\n",
      "Epoch 25/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.0870 - policy_loss: 0.8910 - value_loss: 0.1546\n",
      "Epoch 26/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.2283 - policy_loss: 1.0325 - value_loss: 0.1543\n",
      "Epoch 27/128\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 1.0785 - policy_loss: 0.8933 - value_loss: 0.1437\n",
      "Epoch 28/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.9999 - policy_loss: 0.8204 - value_loss: 0.1378\n",
      "Epoch 29/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.9573 - policy_loss: 0.7729 - value_loss: 0.1426\n",
      "Epoch 30/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.9045 - policy_loss: 0.7209 - value_loss: 0.1417\n",
      "Epoch 31/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.8470 - policy_loss: 0.6746 - value_loss: 0.1304\n",
      "Epoch 32/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.8580 - policy_loss: 0.6912 - value_loss: 0.1248\n",
      "Epoch 33/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.7179 - policy_loss: 0.5486 - value_loss: 0.1272\n",
      "Epoch 34/128\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.7997 - policy_loss: 0.6363 - value_loss: 0.1211\n",
      "Epoch 35/128\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.6432 - policy_loss: 0.4713 - value_loss: 0.1295\n",
      "Epoch 36/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.7044 - policy_loss: 0.5400 - value_loss: 0.1220\n",
      "Epoch 37/128\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.6552 - policy_loss: 0.4894 - value_loss: 0.1233\n",
      "Epoch 38/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.6300 - policy_loss: 0.4716 - value_loss: 0.1159\n",
      "Epoch 39/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.5613 - policy_loss: 0.4039 - value_loss: 0.1147\n",
      "Epoch 40/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.4935 - policy_loss: 0.3372 - value_loss: 0.1136\n",
      "Epoch 41/128\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.5448 - policy_loss: 0.3929 - value_loss: 0.1091\n",
      "Epoch 42/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.5175 - policy_loss: 0.3680 - value_loss: 0.1064\n",
      "Epoch 43/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.4374 - policy_loss: 0.3003 - value_loss: 0.0941\n",
      "Epoch 44/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.4273 - policy_loss: 0.2845 - value_loss: 0.0997\n",
      "Epoch 45/128\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3568 - policy_loss: 0.2201 - value_loss: 0.0935\n",
      "Epoch 46/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3457 - policy_loss: 0.2121 - value_loss: 0.0905\n",
      "Epoch 47/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3945 - policy_loss: 0.2601 - value_loss: 0.0912\n",
      "Epoch 48/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.4012 - policy_loss: 0.2635 - value_loss: 0.0944\n",
      "Epoch 49/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3560 - policy_loss: 0.2256 - value_loss: 0.0870\n",
      "Epoch 50/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3066 - policy_loss: 0.1836 - value_loss: 0.0795\n",
      "Epoch 51/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.3002 - policy_loss: 0.1461 - value_loss: 0.1107\n",
      "Epoch 52/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.3107 - policy_loss: 0.1857 - value_loss: 0.0814\n",
      "Epoch 53/128\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.2343 - policy_loss: 0.1151 - value_loss: 0.0755\n",
      "Epoch 54/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2385 - policy_loss: 0.1265 - value_loss: 0.0683\n",
      "Epoch 55/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2775 - policy_loss: 0.1655 - value_loss: 0.0683\n",
      "Epoch 56/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2621 - policy_loss: 0.1493 - value_loss: 0.0691\n",
      "Epoch 57/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1815 - policy_loss: 0.0798 - value_loss: 0.0579\n",
      "Epoch 58/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2313 - policy_loss: 0.1259 - value_loss: 0.0616\n",
      "Epoch 59/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1988 - policy_loss: 0.1048 - value_loss: 0.0502\n",
      "Epoch 60/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2179 - policy_loss: 0.1204 - value_loss: 0.0537\n",
      "Epoch 61/128\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.1886 - policy_loss: 0.0956 - value_loss: 0.0491\n",
      "Epoch 62/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2081 - policy_loss: 0.1026 - value_loss: 0.0616\n",
      "Epoch 63/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1878 - policy_loss: 0.0941 - value_loss: 0.0498\n",
      "Epoch 64/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1761 - policy_loss: 0.0817 - value_loss: 0.0503\n",
      "Epoch 65/128\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.1962 - policy_loss: 0.0988 - value_loss: 0.0533\n",
      "Epoch 66/128\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.1687 - policy_loss: 0.0791 - value_loss: 0.0455\n",
      "Epoch 67/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 83ms/step - loss: 0.1714 - policy_loss: 0.0772 - value_loss: 0.0501\n",
      "Epoch 68/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1641 - policy_loss: 0.0721 - value_loss: 0.0478\n",
      "Epoch 69/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1780 - policy_loss: 0.0896 - value_loss: 0.0442\n",
      "Epoch 70/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1504 - policy_loss: 0.0652 - value_loss: 0.0410\n",
      "Epoch 71/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1327 - policy_loss: 0.0559 - value_loss: 0.0325\n",
      "Epoch 72/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.1432 - policy_loss: 0.0504 - value_loss: 0.0486\n",
      "Epoch 73/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1101 - policy_loss: 0.0358 - value_loss: 0.0300\n",
      "Epoch 74/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0966 - policy_loss: 0.0267 - value_loss: 0.0256\n",
      "Epoch 75/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1015 - policy_loss: 0.0249 - value_loss: 0.0322\n",
      "Epoch 76/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1079 - policy_loss: 0.0286 - value_loss: 0.0349\n",
      "Epoch 77/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.1005 - policy_loss: 0.0232 - value_loss: 0.0329\n",
      "Epoch 78/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0890 - policy_loss: 0.0182 - value_loss: 0.0264\n",
      "Epoch 79/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0849 - policy_loss: 0.0176 - value_loss: 0.0229\n",
      "Epoch 80/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0964 - policy_loss: 0.0267 - value_loss: 0.0253\n",
      "Epoch 81/128\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0838 - policy_loss: 0.0187 - value_loss: 0.0208\n",
      "Epoch 82/128\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0754 - policy_loss: 0.0142 - value_loss: 0.0169\n",
      "Epoch 83/128\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0791 - policy_loss: 0.0192 - value_loss: 0.0156\n",
      "Epoch 84/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0794 - policy_loss: 0.0155 - value_loss: 0.0195\n",
      "Epoch 85/128\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.0729 - policy_loss: 0.0131 - value_loss: 0.0155\n",
      "Epoch 86/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0756 - policy_loss: 0.0119 - value_loss: 0.0194\n",
      "Epoch 87/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0748 - policy_loss: 0.0142 - value_loss: 0.0163\n",
      "Epoch 88/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0735 - policy_loss: 0.0136 - value_loss: 0.0156\n",
      "Epoch 89/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0721 - policy_loss: 0.0108 - value_loss: 0.0171\n",
      "Epoch 90/128\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0678 - policy_loss: 0.0088 - value_loss: 0.0148\n",
      "Epoch 91/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0677 - policy_loss: 0.0082 - value_loss: 0.0154\n",
      "Epoch 92/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0676 - policy_loss: 0.0112 - value_loss: 0.0122\n",
      "Epoch 93/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0667 - policy_loss: 0.0097 - value_loss: 0.0129\n",
      "Epoch 94/128\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0621 - policy_loss: 0.0083 - value_loss: 0.0097\n",
      "Epoch 95/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0686 - policy_loss: 0.0097 - value_loss: 0.0148\n",
      "Epoch 96/128\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0617 - policy_loss: 0.0083 - value_loss: 0.0093\n",
      "Epoch 97/128\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.0614 - policy_loss: 0.0082 - value_loss: 0.0092\n",
      "Epoch 98/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0621 - policy_loss: 0.0093 - value_loss: 0.0087\n",
      "Epoch 99/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0584 - policy_loss: 0.0080 - value_loss: 0.0064\n",
      "Epoch 100/128\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0558 - policy_loss: 0.0064 - value_loss: 0.0054\n",
      "Epoch 101/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0607 - policy_loss: 0.0084 - value_loss: 0.0084\n",
      "Epoch 102/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0579 - policy_loss: 0.0062 - value_loss: 0.0077\n",
      "Epoch 103/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0568 - policy_loss: 0.0061 - value_loss: 0.0067\n",
      "Epoch 104/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0581 - policy_loss: 0.0066 - value_loss: 0.0076\n",
      "Epoch 105/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0585 - policy_loss: 0.0057 - value_loss: 0.0089\n",
      "Epoch 106/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0597 - policy_loss: 0.0066 - value_loss: 0.0092\n",
      "Epoch 107/128\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.0564 - policy_loss: 0.0061 - value_loss: 0.0065\n",
      "Epoch 108/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0564 - policy_loss: 0.0059 - value_loss: 0.0067\n",
      "Epoch 109/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0592 - policy_loss: 0.0065 - value_loss: 0.0089\n",
      "Epoch 110/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0553 - policy_loss: 0.0049 - value_loss: 0.0066\n",
      "Epoch 111/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0544 - policy_loss: 0.0045 - value_loss: 0.0062\n",
      "Epoch 112/128\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0548 - policy_loss: 0.0054 - value_loss: 0.0057\n",
      "Epoch 113/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0544 - policy_loss: 0.0039 - value_loss: 0.0067\n",
      "Epoch 114/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0555 - policy_loss: 0.0049 - value_loss: 0.0069\n",
      "Epoch 115/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0541 - policy_loss: 0.0053 - value_loss: 0.0052\n",
      "Epoch 116/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0531 - policy_loss: 0.0041 - value_loss: 0.0054\n",
      "Epoch 117/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0511 - policy_loss: 0.0037 - value_loss: 0.0038\n",
      "Epoch 118/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0544 - policy_loss: 0.0060 - value_loss: 0.0049\n",
      "Epoch 119/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0558 - policy_loss: 0.0038 - value_loss: 0.0084\n",
      "Epoch 120/128\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.0521 - policy_loss: 0.0034 - value_loss: 0.0052\n",
      "Epoch 121/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0520 - policy_loss: 0.0051 - value_loss: 0.0035\n",
      "Epoch 122/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0531 - policy_loss: 0.0049 - value_loss: 0.0048\n",
      "Epoch 123/128\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.0526 - policy_loss: 0.0043 - value_loss: 0.0049\n",
      "Epoch 124/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0526 - policy_loss: 0.0042 - value_loss: 0.0050\n",
      "Epoch 125/128\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0515 - policy_loss: 0.0041 - value_loss: 0.0040\n",
      "Epoch 126/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0512 - policy_loss: 0.0034 - value_loss: 0.0044\n",
      "Epoch 127/128\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.0511 - policy_loss: 0.0033 - value_loss: 0.0045\n",
      "Epoch 128/128\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0506 - policy_loss: 0.0036 - value_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "#sess = K.get_session()\n",
    "#sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "#K.set_session(sess)\n",
    "\n",
    "# Training\n",
    "callbacks = []\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=modelPath+\".checkpoint\", save_weights_only=False)\n",
    "callbacks.append(checkpoint)\n",
    "\n",
    "progbar = ProgbarLogger()\n",
    "callbacks.append(progbar)\n",
    "\n",
    "#tensorboard = TensorBoard(log_dir='model/log2', write_grads=True, write_graph=True, write_images=True, histogram_freq=1)\n",
    "#callbacks.append(tensorboard)\n",
    "\n",
    "model.fit_generator(data_generator, epochs=128, steps_per_epoch=len(data_generator)) #, callbacks=callbacks)\n",
    "\n",
    "model.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesToDotsAndBoxesImage(lines, imgWidth, imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=lines.dtype)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = lines[idx]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: 26\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  99]]\n",
      "1.0\n",
      "input (15, 17): \n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215 255 215   0 215 255 215   0 215 255 215 255 215   0 215   0]\n",
      " [  0   0   0 255   0   0   0 255   0 255   0   0   0   0   0 255   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0 215 255 215   0]\n",
      " [  0 255   0 255   0 255   0 255   0   0   0   0   0 255   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215 255 215   0 215 255 215   0 215   0]\n",
      " [  0   0   0 255   0 255   0   0   0 255   0 255   0   0   0 255   0]\n",
      " [  0 215 255 215   0 215   0 215   0 215   0 215   0 215 255 215   0]\n",
      " [  0 255   0   0   0 255   0   0   0   0   0 255   0   0   0   0   0]\n",
      " [  0 215   0 215 255 215 255 215 255 215 255 215   0 215 255 215   0]\n",
      " [  0   0   0 255   0   0   0 255   0   0   0 255   0 255   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0 255   0 255   0 255   0   0   0   0   0 255   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215 255 215 255 215 255 215 255 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "prediction policy: \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 99  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "prediction value: \n",
      "[[-0.41]]\n",
      "target value: \n",
      "[-0.38]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKoAAACWCAIAAADBrIQDAAAB+0lEQVR4nO3dQWoCQRBA0SR4mHj/\nw5jDBJKtG9tg0+nR/952GLrhMxspyrc3AAAAAOC1vI8fX4ZPP4dPv4ZPz7Fzd915/O7H8CkvTv40\n+dPkT5M/Tf40+dPkT5M/7c6vfjN+Nh08c+6uO8+YubOvP03+NPnT5E+TP03+NPnT5E+TP+00fjwz\nRzaeXzvmubvuvG7GcMzXnyZ/mvxp8qfJnyZ/mvxp8qfJn3ZnfG3X3Jx5vWvr7uzrT5M/Tf40+dPk\nT5M/Tf40+dPkT7sz67drbm7du+Pf1465E3DMXj8eJH+a/Gnyp8mfJn+a/Gnyp8mfdtC9fnYC/p29\nfjxI/jT50+RPkz9N/jT50+RPkz9taq/fuvk1OwGv2evHEvKnyZ8mf5r8afKnyZ8mf5r8aQv3+s2w\nm+9/+PrT5E+TP03+NPnT5E+TP03+NPnTFu71Wze/NrObb+bcXbv5Zs6114+b5E+TP03+NPnT5E+T\nP03+NPnTDrrXr3au//BlA/nT5E+TP03+NPnT5E+TP03+tKm9fut25NXO9R++bCB/mvxp8qfJnyZ/\nmvxp8qfJn7Zwr98zzr7NeMY7+/rT5E+TP03+NPnT5E+TP03+NPnTFu71W/fuM+71m7nz+Xv09uU0\n+kXRrB83yZ8mf5r8afKnyZ8mf5r8afIDAAAAALyQXxYuVBsu9ggJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=170x150 at 0x7F8390A25110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.randrange(x_input_raw.shape[0])\n",
    "print(\"example: \"+str(example))\n",
    "\n",
    "input_data = process_input(x_input_raw[example:example+1])\n",
    "\n",
    "(prediction_lines, prediction_value) = model.predict(input_data)\n",
    "prediction_lines_print = prediction_lines * 100\n",
    "print(prediction_lines_print.astype(np.uint8))\n",
    "print(np.sum(prediction_lines))\n",
    "prediction = linesToDotsAndBoxesImage(prediction_lines[0], imgWidth, imgHeight)\n",
    "\n",
    "# print input data\n",
    "input_data_print = x_input_raw[example]\n",
    "print(\"input \"+str(input_data_print.shape)+\": \")\n",
    "print(input_data_print)\n",
    "\n",
    "# generate greyscale image data from input data\n",
    "input_imgdata = x_input_raw[example]\n",
    "\n",
    "# print prediction\n",
    "prediction_data_print = prediction * 100 \n",
    "prediction_data_print = prediction_data_print.astype(np.uint8)\n",
    "print(\"prediction policy: \")\n",
    "print(prediction_data_print)\n",
    "\n",
    "print(\"prediction value: \")\n",
    "print(prediction_value)\n",
    "\n",
    "print(\"target value: \")\n",
    "print(y_value_raw[example])\n",
    "\n",
    "# generate greyscale image data from prediction data\n",
    "prediction_imgdata = prediction * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# generate greyscale image of target data\n",
    "target_imgdata = y_policy_raw[example]\n",
    "\n",
    "# merge image data in color channels\n",
    "merged_imgdata = np.stack([input_imgdata, prediction_imgdata, target_imgdata], axis=2)\n",
    "\n",
    "#create image\n",
    "img = Image.fromarray(merged_imgdata, 'RGB')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
