{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero version 6\n",
    "\n",
    "First AlphaZero version with a value output. \n",
    "This model was trained from scratch on 1.000.000 training examples from the StageThree dataset on a 5x4 board. The model was trained for 32 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from LineFilterLayer import LineFilterLayer\n",
    "\n",
    "modelPath = 'model/alphaZeroV6.h5'\n",
    "\n",
    "datasetPath = 'StageThree-1000000-5x4-22:56-19_04_2018.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(K.image_data_format()) \n",
    "# expected output: channels_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotsAndBoxesToCategorical(inputData):\n",
    "    inp = np.copy(inputData)\n",
    "    inp[inp == 255] = 1 # Line - comes first so that target data only has two categories\n",
    "    inp[inp == 65] = 2 # Box A\n",
    "    inp[inp == 150] = 3 # Box B\n",
    "    inp[inp == 215] = 4 # Dot\n",
    "    cat = to_categorical(inp)\n",
    "    newShape = inp.shape + (cat.shape[-1],)\n",
    "    return cat.reshape(newShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgSizeToBoxes(x):\n",
    "    return (x-3)/2\n",
    "\n",
    "def lineFilterMatrixNP(imgWidth,imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=np.bool)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = 1\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPVDataset(datasetPath):\n",
    "    rawDataset = np.load(datasetPath)\n",
    "    \n",
    "    x_input = rawDataset['input']\n",
    "    y_policy = rawDataset['policy']\n",
    "    y_value = rawDataset['value']\n",
    "    \n",
    "    x_input = dotsAndBoxesToCategorical(x_input)\n",
    "    y_policy = y_policy[:,lineFilterMatrixNP(y_policy.shape[-1], y_policy.shape[-2])]\n",
    "    y_policy /= 255\n",
    "    \n",
    "    return (x_input, y_policy, y_value)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "(x_input, y_policy, y_value) = loadPVDataset(datasetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 11, 13, 5)\n",
      "(1000000, 49)\n",
      "(1000000, 1)\n",
      "input:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "policy:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "value:\n",
      "[-0.88]\n"
     ]
    }
   ],
   "source": [
    "print(x_input.shape)\n",
    "print(y_policy.shape)\n",
    "print(y_value.shape)\n",
    "print(\"input:\")\n",
    "print(x_input[0,::,::,1])\n",
    "print(\"policy:\")\n",
    "print(y_policy[0])\n",
    "print('value:')\n",
    "print(y_value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1                       : (None, 11, 13, 5)\n",
      "input_conv                    : (None, 11, 13, 64)\n",
      "input_relu                    : (None, 11, 13, 64)\n",
      "batch_normalization_1         : (None, 11, 13, 64)\n",
      "res1_conv1_64                 : (None, 11, 13, 64)\n",
      "res1_batchnorm1               : (None, 11, 13, 64)\n",
      "res1_relu1                    : (None, 11, 13, 64)\n",
      "res1_conv2-64                 : (None, 11, 13, 64)\n",
      "res1_batchnorm2               : (None, 11, 13, 64)\n",
      "res1_add                      : (None, 11, 13, 64)\n",
      "res1_relu2                    : (None, 11, 13, 64)\n",
      "res2_conv1_64                 : (None, 11, 13, 64)\n",
      "res2_batchnorm1               : (None, 11, 13, 64)\n",
      "res2_relu1                    : (None, 11, 13, 64)\n",
      "res2_conv2-64                 : (None, 11, 13, 64)\n",
      "res2_batchnorm2               : (None, 11, 13, 64)\n",
      "res2_add                      : (None, 11, 13, 64)\n",
      "res2_relu2                    : (None, 11, 13, 64)\n",
      "res3_conv1_64                 : (None, 11, 13, 64)\n",
      "res3_batchnorm1               : (None, 11, 13, 64)\n",
      "res3_relu1                    : (None, 11, 13, 64)\n",
      "res3_conv2-64                 : (None, 11, 13, 64)\n",
      "res3_batchnorm2               : (None, 11, 13, 64)\n",
      "res3_add                      : (None, 11, 13, 64)\n",
      "res3_relu2                    : (None, 11, 13, 64)\n",
      "res4_conv1_64                 : (None, 11, 13, 64)\n",
      "res4_batchnorm1               : (None, 11, 13, 64)\n",
      "res4_relu1                    : (None, 11, 13, 64)\n",
      "res4_conv2-64                 : (None, 11, 13, 64)\n",
      "res4_batchnorm2               : (None, 11, 13, 64)\n",
      "res4_add                      : (None, 11, 13, 64)\n",
      "res4_relu2                    : (None, 11, 13, 64)\n",
      "value_conv                    : (None, 11, 13, 1)\n",
      "policy_conv                   : (None, 11, 13, 1)\n",
      "flatten_1                     : (None, 143)\n",
      "line_filter_layer_1           : (None, 49)\n",
      "value_dense                   : (None, 1)\n",
      "<tf.Variable 'value_dense/kernel:0' shape=(143, 1) dtype=float32_ref>\n",
      "policy_softmax                : (None, 49)\n",
      "value_tanh                    : (None, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 11, 13, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_conv (Conv2D)             (None, 11, 13, 64)   8064        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_relu (Activation)         (None, 11, 13, 64)   0           input_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 11, 13, 64)   256         input_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res1_conv1_64 (Conv2D)          (None, 11, 13, 64)   102464      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res1_batchnorm1 (BatchNormaliza (None, 11, 13, 64)   256         res1_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1_relu1 (Activation)         (None, 11, 13, 64)   0           res1_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res1_conv2-64 (Conv2D)          (None, 11, 13, 64)   102464      res1_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res1_batchnorm2 (BatchNormaliza (None, 11, 13, 64)   256         res1_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1_add (Add)                  (None, 11, 13, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 res1_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res1_relu2 (Activation)         (None, 11, 13, 64)   0           res1_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res2_conv1_64 (Conv2D)          (None, 11, 13, 64)   102464      res1_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2_batchnorm1 (BatchNormaliza (None, 11, 13, 64)   256         res2_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2_relu1 (Activation)         (None, 11, 13, 64)   0           res2_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2_conv2-64 (Conv2D)          (None, 11, 13, 64)   102464      res2_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2_batchnorm2 (BatchNormaliza (None, 11, 13, 64)   256         res2_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2_add (Add)                  (None, 11, 13, 64)   0           res1_relu2[0][0]                 \n",
      "                                                                 res2_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2_relu2 (Activation)         (None, 11, 13, 64)   0           res2_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res3_conv1_64 (Conv2D)          (None, 11, 13, 64)   102464      res2_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3_batchnorm1 (BatchNormaliza (None, 11, 13, 64)   256         res3_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3_relu1 (Activation)         (None, 11, 13, 64)   0           res3_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_conv2-64 (Conv2D)          (None, 11, 13, 64)   102464      res3_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3_batchnorm2 (BatchNormaliza (None, 11, 13, 64)   256         res3_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3_add (Add)                  (None, 11, 13, 64)   0           res2_relu2[0][0]                 \n",
      "                                                                 res3_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_relu2 (Activation)         (None, 11, 13, 64)   0           res3_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res4_conv1_64 (Conv2D)          (None, 11, 13, 64)   102464      res3_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4_batchnorm1 (BatchNormaliza (None, 11, 13, 64)   256         res4_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4_relu1 (Activation)         (None, 11, 13, 64)   0           res4_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4_conv2-64 (Conv2D)          (None, 11, 13, 64)   102464      res4_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4_batchnorm2 (BatchNormaliza (None, 11, 13, 64)   256         res4_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4_add (Add)                  (None, 11, 13, 64)   0           res3_relu2[0][0]                 \n",
      "                                                                 res4_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4_relu2 (Activation)         (None, 11, 13, 64)   0           res4_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "value_conv (Conv2D)             (None, 11, 13, 1)    1601        res4_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "policy_conv (Conv2D)            (None, 11, 13, 1)    1601        res4_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 143)          0           value_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "line_filter_layer_1 (LineFilter (None, 49)           0           policy_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "value_dense (Dense)             (None, 1)            143         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "policy_softmax (Activation)     (None, 49)           0           line_filter_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "value_tanh (Activation)         (None, 1)            0           value_dense[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 833,425\n",
      "Trainable params: 832,130\n",
      "Non-trainable params: 1,295\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernelSize = (5,5)\n",
    "filterCnt = 64\n",
    "l2reg = 1e-4\n",
    "resBlockCnt = 4\n",
    "imgWidth = x_input.shape[-2]\n",
    "imgHeight = x_input.shape[-3]\n",
    "\n",
    "def build_residual_block(x, index):\n",
    "        in_x = x\n",
    "        res_name = \"res\"+str(index)\n",
    "        x = Conv2D(filters=filterCnt, kernel_size=kernelSize, padding=\"same\",\n",
    "                   data_format=\"channels_last\", kernel_regularizer=l2(l2reg), \n",
    "                   name=res_name+\"_conv1_\"+str(filterCnt))(x)\n",
    "        x = BatchNormalization(name=res_name+\"_batchnorm1\")(x)\n",
    "        x = Activation(\"relu\",name=res_name+\"_relu1\")(x)\n",
    "        x = Conv2D(filters=filterCnt, kernel_size=kernelSize, padding=\"same\",\n",
    "                   data_format=\"channels_last\", kernel_regularizer=l2(l2reg), \n",
    "                   name=res_name+\"_conv2-\"+str(filterCnt))(x)\n",
    "        x = BatchNormalization(name=\"res\"+str(index)+\"_batchnorm2\")(x)\n",
    "        x = Add(name=res_name+\"_add\")([in_x, x])\n",
    "        x = Activation(\"relu\", name=res_name+\"_relu2\")(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "img_input = Input(shape=(imgHeight,imgWidth,5,))\n",
    "x = Conv2D(filterCnt, kernelSize, padding='same', kernel_regularizer=l2(l2reg), name=\"input_conv\")(img_input)\n",
    "x = Activation(\"relu\", name=\"input_relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for i in range(resBlockCnt):\n",
    "    x = build_residual_block(x, i+1)\n",
    "\n",
    "res_out = x\n",
    "\n",
    "# policy output\n",
    "x = Conv2D(1, kernelSize, padding='same', kernel_regularizer=l2(l2reg), name=\"policy_conv\")(x)\n",
    "x = LineFilterLayer(imgWidth, imgHeight)(x)\n",
    "x = Activation(\"softmax\", name=\"policy_softmax\")(x)\n",
    "policy_output = x\n",
    "\n",
    "# value output\n",
    "x = Conv2D(1, kernelSize, padding='same', kernel_regularizer=l2(l2reg), name=\"value_conv\")(res_out)\n",
    "#x = LineFilterLayer(imgWidth, imgHeight)(x)\n",
    "#x = Conv2D(filters=1, kernel_size=1, use_bias=False, kernel_regularizer=l2(l2reg), name=\"value_conv\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1, trainable=False, kernel_initializer=Constant(1.0/(imgWidth*imgHeight)), use_bias=False, name=\"value_dense\")(x)\n",
    "x = Activation(\"tanh\", name=\"value_tanh\")(x)\n",
    "value_output = x\n",
    "    \n",
    "model = Model(inputs=img_input, outputs=[policy_output, value_output])\n",
    "model.compile(optimizer='adam', loss=['categorical_crossentropy', 'mean_squared_error'])\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(\"{:30}: {}\".format(layer.name, layer.output_shape))\n",
    "    if layer.name is 'value_dense':\n",
    "        print(layer.kernel)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 999000 samples, validate on 1000 samples\n",
      "Epoch 1/32\n",
      "Epoch 1/32\n",
      "999000/999000 [==============================] - 764s 765us/step - loss: 1.3799 - policy_softmax_loss: 1.0871 - value_tanh_loss: 0.2222 - val_loss: 1.2723 - val_policy_softmax_loss: 0.9926 - val_value_tanh_loss: 0.2155\n",
      "999000/999000 [==============================] - 764s 765us/step - loss: 1.3799 - policy_softmax_loss: 1.0871 - value_tanh_loss: 0.2222 - val_loss: 1.2723 - val_policy_softmax_loss: 0.9926 - val_value_tanh_loss: 0.2155\n",
      "Epoch 2/32\n",
      "Epoch 2/32\n",
      "999000/999000 [==============================] - 766s 767us/step - loss: 1.2500 - policy_softmax_loss: 1.0048 - value_tanh_loss: 0.1872 - val_loss: 1.2092 - val_policy_softmax_loss: 0.9748 - val_value_tanh_loss: 0.1808\n",
      "999000/999000 [==============================] - 766s 767us/step - loss: 1.2500 - policy_softmax_loss: 1.0048 - value_tanh_loss: 0.1872 - val_loss: 1.2092 - val_policy_softmax_loss: 0.9748 - val_value_tanh_loss: 0.1808\n",
      "Epoch 3/32\n",
      "Epoch 3/32\n",
      "999000/999000 [==============================] - 798s 799us/step - loss: 1.2240 - policy_softmax_loss: 0.9933 - value_tanh_loss: 0.1799 - val_loss: 1.1839 - val_policy_softmax_loss: 0.9555 - val_value_tanh_loss: 0.1798\n",
      "999000/999000 [==============================] - 798s 799us/step - loss: 1.2240 - policy_softmax_loss: 0.9933 - value_tanh_loss: 0.1799 - val_loss: 1.1839 - val_policy_softmax_loss: 0.9555 - val_value_tanh_loss: 0.1798\n",
      "Epoch 4/32\n",
      "Epoch 4/32\n",
      "999000/999000 [==============================] - 784s 785us/step - loss: 1.2134 - policy_softmax_loss: 0.9883 - value_tanh_loss: 0.1776 - val_loss: 1.1873 - val_policy_softmax_loss: 0.9611 - val_value_tanh_loss: 0.1796 - po\n",
      "999000/999000 [==============================] - 784s 785us/step - loss: 1.2134 - policy_softmax_loss: 0.9883 - value_tanh_loss: 0.1776 - val_loss: 1.1873 - val_policy_softmax_loss: 0.9611 - val_value_tanh_loss: 0.1796\n",
      "Epoch 5/32\n",
      "Epoch 5/32\n",
      "999000/999000 [==============================] - 784s 785us/step - loss: 1.2076 - policy_softmax_loss: 0.9858 - value_tanh_loss: 0.1759 - val_loss: 1.1736 - val_policy_softmax_loss: 0.9502 - val_value_tanh_loss: 0.1782\n",
      "999000/999000 [==============================] - 785s 785us/step - loss: 1.2076 - policy_softmax_loss: 0.9858 - value_tanh_loss: 0.1759 - val_loss: 1.1736 - val_policy_softmax_loss: 0.9502 - val_value_tanh_loss: 0.1782\n",
      "Epoch 6/32\n",
      "Epoch 6/32\n",
      "999000/999000 [==============================] - 784s 785us/step - loss: 1.2036 - policy_softmax_loss: 0.9838 - value_tanh_loss: 0.1747 - val_loss: 1.2402 - val_policy_softmax_loss: 0.9777 - val_value_tanh_loss: 0.2176ax_loss: 0.9838 -\n",
      "999000/999000 [==============================] - 784s 785us/step - loss: 1.2036 - policy_softmax_loss: 0.9838 - value_tanh_loss: 0.1747 - val_loss: 1.2402 - val_policy_softmax_loss: 0.9777 - val_value_tanh_loss: 0.2176\n",
      "Epoch 7/32\n",
      "Epoch 7/32\n",
      "999000/999000 [==============================] - 782s 783us/step - loss: 1.2005 - policy_softmax_loss: 0.9823 - value_tanh_loss: 0.1737 - val_loss: 1.1690 - val_policy_softmax_loss: 0.9487 - val_value_tanh_loss: 0.1764\n",
      "999000/999000 [==============================] - 782s 783us/step - loss: 1.2005 - policy_softmax_loss: 0.9823 - value_tanh_loss: 0.1737 - val_loss: 1.1690 - val_policy_softmax_loss: 0.9487 - val_value_tanh_loss: 0.1764\n",
      "Epoch 8/32\n",
      "Epoch 8/32\n",
      "999000/999000 [==============================] - 781s 782us/step - loss: 1.1982 - policy_softmax_loss: 0.9813 - value_tanh_loss: 0.1729 - val_loss: 1.1855 - val_policy_softmax_loss: 0.9576 - val_value_tanh_loss: 0.1846loss: 1.1982 - policy_softmax_loss: 0.9814 - value_t - ETA: 0s - loss: 1.1982 - policy_softmax_loss: 0.9813 - val\n",
      "999000/999000 [==============================] - 781s 782us/step - loss: 1.1982 - policy_softmax_loss: 0.9813 - value_tanh_loss: 0.1729 - val_loss: 1.1855 - val_policy_softmax_loss: 0.9576 - val_value_tanh_loss: 0.1846\n",
      "Epoch 9/32\n",
      "Epoch 9/32\n",
      "999000/999000 [==============================] - 779s 779us/step - loss: 1.1966 - policy_softmax_loss: 0.9804 - value_tanh_loss: 0.1727 - val_loss: 1.1686 - val_policy_softmax_loss: 0.9501 - val_value_tanh_loss: 0.1754\n",
      "999000/999000 [==============================] - 779s 779us/step - loss: 1.1966 - policy_softmax_loss: 0.9804 - value_tanh_loss: 0.1727 - val_loss: 1.1686 - val_policy_softmax_loss: 0.9501 - val_value_tanh_loss: 0.1754\n",
      "Epoch 10/32\n",
      "Epoch 10/32\n",
      "999000/999000 [==============================] - 777s 778us/step - loss: 1.1955 - policy_softmax_loss: 0.9799 - value_tanh_loss: 0.1723 - val_loss: 1.1736 - val_policy_softmax_loss: 0.9559 - val_value_tanh_loss: 0.1751\n",
      "999000/999000 [==============================] - 777s 778us/step - loss: 1.1955 - policy_softmax_loss: 0.9799 - value_tanh_loss: 0.1723 - val_loss: 1.1736 - val_policy_softmax_loss: 0.9559 - val_value_tanh_loss: 0.1751\n",
      "Epoch 11/32\n",
      "Epoch 11/32\n",
      "999000/999000 [==============================] - 777s 777us/step - loss: 1.1940 - policy_softmax_loss: 0.9792 - value_tanh_loss: 0.1720 - val_loss: 1.1826 - val_policy_softmax_loss: 0.9649 - val_value_tanh_loss: 0.1749\n",
      "999000/999000 [==============================] - 777s 777us/step - loss: 1.1940 - policy_softmax_loss: 0.9792 - value_tanh_loss: 0.1720 - val_loss: 1.1826 - val_policy_softmax_loss: 0.9649 - val_value_tanh_loss: 0.1749\n",
      "Epoch 12/32\n",
      "Epoch 12/32\n",
      "999000/999000 [==============================] - 777s 778us/step - loss: 1.1928 - policy_softmax_loss: 0.9786 - value_tanh_loss: 0.1718 - val_loss: 1.1584 - val_policy_softmax_loss: 0.9413 - val_value_tanh_loss: 0.1751: 0.17\n",
      "999000/999000 [==============================] - 777s 778us/step - loss: 1.1928 - policy_softmax_loss: 0.9786 - value_tanh_loss: 0.1718 - val_loss: 1.1584 - val_policy_softmax_loss: 0.9413 - val_value_tanh_loss: 0.1751\n",
      "Epoch 13/32\n",
      "Epoch 13/32\n",
      "999000/999000 [==============================] - 778s 779us/step - loss: 1.1919 - policy_softmax_loss: 0.9784 - value_tanh_loss: 0.1715 - val_loss: 1.1556 - val_policy_softmax_loss: 0.9424 - val_value_tanh_loss: 0.1716 1.1919 - policy_softmax\n",
      "999000/999000 [==============================] - 778s 779us/step - loss: 1.1919 - policy_softmax_loss: 0.9784 - value_tanh_loss: 0.1715 - val_loss: 1.1556 - val_policy_softmax_loss: 0.9424 - val_value_tanh_loss: 0.1716\n",
      "Epoch 14/32\n",
      "Epoch 14/32\n",
      "999000/999000 [==============================] - 776s 777us/step - loss: 1.1904 - policy_softmax_loss: 0.9778 - value_tanh_loss: 0.1711 - val_loss: 1.1605 - val_policy_softmax_loss: 0.9516 - val_value_tanh_loss: 0.1674\n",
      "999000/999000 [==============================] - 776s 777us/step - loss: 1.1904 - policy_softmax_loss: 0.9778 - value_tanh_loss: 0.1711 - val_loss: 1.1605 - val_policy_softmax_loss: 0.9516 - val_value_tanh_loss: 0.1674\n",
      "Epoch 15/32\n",
      "Epoch 15/32\n",
      "999000/999000 [==============================] - 776s 777us/step - loss: 1.1902 - policy_softmax_loss: 0.9779 - value_tanh_loss: 0.1708 - val_loss: 1.1546 - val_policy_softmax_loss: 0.9378 - val_value_tanh_loss: 0.1756\n",
      "999000/999000 [==============================] - 776s 777us/step - loss: 1.1902 - policy_softmax_loss: 0.9779 - value_tanh_loss: 0.1708 - val_loss: 1.1546 - val_policy_softmax_loss: 0.9378 - val_value_tanh_loss: 0.1756\n",
      "Epoch 16/32\n",
      "Epoch 16/32\n",
      "999000/999000 [==============================] - 778s 779us/step - loss: 1.1892 - policy_softmax_loss: 0.9775 - value_tanh_loss: 0.1704 - val_loss: 1.1809 - val_policy_softmax_loss: 0.9654 - val_value_tanh_loss: 0.1744 loss: 1.1892  - ETA: 3s - loss: 1.1891 - polic - ETA: 1s - loss: 1.1891 - poli\n",
      "999000/999000 [==============================] - 778s 779us/step - loss: 1.1892 - policy_softmax_loss: 0.9775 - value_tanh_loss: 0.1704 - val_loss: 1.1809 - val_policy_softmax_loss: 0.9654 - val_value_tanh_loss: 0.1744\n",
      "Epoch 17/32\n",
      "Epoch 17/32\n",
      "999000/999000 [==============================] - 760s 761us/step - loss: 1.1880 - policy_softmax_loss: 0.9770 - value_tanh_loss: 0.1700 - val_loss: 1.1669 - val_policy_softmax_loss: 0.9528 - val_value_tanh_loss: 0.1730\n",
      "999000/999000 [==============================] - 760s 761us/step - loss: 1.1880 - policy_softmax_loss: 0.9770 - value_tanh_loss: 0.1700 - val_loss: 1.1669 - val_policy_softmax_loss: 0.9528 - val_value_tanh_loss: 0.1730\n",
      "Epoch 18/32\n",
      "Epoch 18/32\n",
      "999000/999000 [==============================] - 751s 751us/step - loss: 1.1874 - policy_softmax_loss: 0.9768 - value_tanh_loss: 0.1697 - val_loss: 1.1479 - val_policy_softmax_loss: 0.9376 - val_value_tanh_loss: 0.1695\n",
      "999000/999000 [==============================] - 751s 751us/step - loss: 1.1874 - policy_softmax_loss: 0.9768 - value_tanh_loss: 0.1697 - val_loss: 1.1479 - val_policy_softmax_loss: 0.9376 - val_value_tanh_loss: 0.1695\n",
      "Epoch 19/32\n",
      "Epoch 19/32\n",
      "999000/999000 [==============================] - 750s 751us/step - loss: 1.1867 - policy_softmax_loss: 0.9764 - value_tanh_loss: 0.1694 - val_loss: 1.1642 - val_policy_softmax_loss: 0.9536 - val_value_tanh_loss: 0.1700\n",
      "999000/999000 [==============================] - 750s 751us/step - loss: 1.1867 - policy_softmax_loss: 0.9764 - value_tanh_loss: 0.1694 - val_loss: 1.1642 - val_policy_softmax_loss: 0.9536 - val_value_tanh_loss: 0.1700\n",
      "Epoch 20/32\n",
      "Epoch 20/32\n",
      "999000/999000 [==============================] - 751s 751us/step - loss: 1.1870 - policy_softmax_loss: 0.9768 - value_tanh_loss: 0.1696 - val_loss: 1.1704 - val_policy_softmax_loss: 0.9493 - val_value_tanh_loss: 0.1805\n",
      "999000/999000 [==============================] - 751s 752us/step - loss: 1.1870 - policy_softmax_loss: 0.9768 - value_tanh_loss: 0.1696 - val_loss: 1.1704 - val_policy_softmax_loss: 0.9493 - val_value_tanh_loss: 0.1805\n",
      "Epoch 21/32\n",
      "Epoch 21/32\n",
      "999000/999000 [==============================] - 751s 752us/step - loss: 1.1859 - policy_softmax_loss: 0.9761 - value_tanh_loss: 0.1694 - val_loss: 1.2022 - val_policy_softmax_loss: 0.9886 - val_value_tanh_loss: 0.1734\n",
      "999000/999000 [==============================] - 751s 752us/step - loss: 1.1859 - policy_softmax_loss: 0.9761 - value_tanh_loss: 0.1694 - val_loss: 1.2022 - val_policy_softmax_loss: 0.9886 - val_value_tanh_loss: 0.1734\n",
      "Epoch 22/32\n",
      "Epoch 22/32\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1855 - policy_softmax_loss: 0.9760 - value_tanh_loss: 0.1692 - val_loss: 1.1614 - val_policy_softmax_loss: 0.9486 - val_value_tanh_loss: 0.1726\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1855 - policy_softmax_loss: 0.9760 - value_tanh_loss: 0.1692 - val_loss: 1.1614 - val_policy_softmax_loss: 0.9486 - val_value_tanh_loss: 0.1726\n",
      "Epoch 23/32\n",
      "Epoch 23/32\n",
      "999000/999000 [==============================] - 752s 752us/step - loss: 1.1851 - policy_softmax_loss: 0.9759 - value_tanh_loss: 0.1690 - val_loss: 1.1598 - val_policy_softmax_loss: 0.9447 - val_value_tanh_loss: 0.1749\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1851 - policy_softmax_loss: 0.9759 - value_tanh_loss: 0.1690 - val_loss: 1.1598 - val_policy_softmax_loss: 0.9447 - val_value_tanh_loss: 0.1749\n",
      "Epoch 24/32\n",
      "Epoch 24/32\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1847 - policy_softmax_loss: 0.9757 - value_tanh_loss: 0.1689 - val_loss: 1.1608 - val_policy_softmax_loss: 0.9506 - val_value_tanh_loss: 0.1700\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1847 - policy_softmax_loss: 0.9757 - value_tanh_loss: 0.1689 - val_loss: 1.1608 - val_policy_softmax_loss: 0.9506 - val_value_tanh_loss: 0.1700\n",
      "Epoch 25/32\n",
      "Epoch 25/32\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1845 - policy_softmax_loss: 0.9755 - value_tanh_loss: 0.1689 - val_loss: 1.1514 - val_policy_softmax_loss: 0.9390 - val_value_tanh_loss: 0.1723\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1845 - policy_softmax_loss: 0.9755 - value_tanh_loss: 0.1689 - val_loss: 1.1514 - val_policy_softmax_loss: 0.9390 - val_value_tanh_loss: 0.1723\n",
      "Epoch 26/32\n",
      "Epoch 26/32\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1839 - policy_softmax_loss: 0.9752 - value_tanh_loss: 0.1688 - val_loss: 1.1511 - val_policy_softmax_loss: 0.9442 - val_value_tanh_loss: 0.1676\n",
      "999000/999000 [==============================] - 752s 753us/step - loss: 1.1839 - policy_softmax_loss: 0.9752 - value_tanh_loss: 0.1688 - val_loss: 1.1511 - val_policy_softmax_loss: 0.9442 - val_value_tanh_loss: 0.1676\n",
      "Epoch 27/32\n",
      "Epoch 27/32\n",
      "999000/999000 [==============================] - 752s 752us/step - loss: 1.1834 - policy_softmax_loss: 0.9750 - value_tanh_loss: 0.1687 - val_loss: 1.1527 - val_policy_softmax_loss: 0.9448 - val_value_tanh_loss: 0.1684\n",
      "999000/999000 [==============================] - 752s 752us/step - loss: 1.1834 - policy_softmax_loss: 0.9750 - value_tanh_loss: 0.1687 - val_loss: 1.1527 - val_policy_softmax_loss: 0.9448 - val_value_tanh_loss: 0.1684\n",
      "Epoch 28/32\n",
      "Epoch 28/32\n",
      "999000/999000 [==============================] - 750s 751us/step - loss: 1.1833 - policy_softmax_loss: 0.9750 - value_tanh_loss: 0.1686 - val_loss: 1.1505 - val_policy_softmax_loss: 0.9393 - val_value_tanh_loss: 0.1712\n",
      "999000/999000 [==============================] - 750s 751us/step - loss: 1.1833 - policy_softmax_loss: 0.9750 - value_tanh_loss: 0.1686 - val_loss: 1.1505 - val_policy_softmax_loss: 0.9393 - val_value_tanh_loss: 0.1712\n",
      "Epoch 29/32\n",
      "Epoch 29/32\n",
      "999000/999000 [==============================] - 749s 750us/step - loss: 1.1828 - policy_softmax_loss: 0.9746 - value_tanh_loss: 0.1685 - val_loss: 1.1857 - val_policy_softmax_loss: 0.9811 - val_value_tanh_loss: 0.1651\n",
      "999000/999000 [==============================] - 749s 750us/step - loss: 1.1828 - policy_softmax_loss: 0.9746 - value_tanh_loss: 0.1685 - val_loss: 1.1857 - val_policy_softmax_loss: 0.9811 - val_value_tanh_loss: 0.1651\n",
      "Epoch 30/32\n",
      "Epoch 30/32\n",
      "999000/999000 [==============================] - 748s 749us/step - loss: 1.1825 - policy_softmax_loss: 0.9744 - value_tanh_loss: 0.1686 - val_loss: 1.1482 - val_policy_softmax_loss: 0.9399 - val_value_tanh_loss: 0.1687\n",
      "999000/999000 [==============================] - 749s 749us/step - loss: 1.1825 - policy_softmax_loss: 0.9744 - value_tanh_loss: 0.1686 - val_loss: 1.1482 - val_policy_softmax_loss: 0.9399 - val_value_tanh_loss: 0.1687\n",
      "Epoch 31/32\n",
      "Epoch 31/32\n",
      "999000/999000 [==============================] - 748s 748us/step - loss: 1.1821 - policy_softmax_loss: 0.9742 - value_tanh_loss: 0.1685 - val_loss: 1.1558 - val_policy_softmax_loss: 0.9449 - val_value_tanh_loss: 0.1715\n",
      "999000/999000 [==============================] - 748s 749us/step - loss: 1.1821 - policy_softmax_loss: 0.9742 - value_tanh_loss: 0.1685 - val_loss: 1.1558 - val_policy_softmax_loss: 0.9449 - val_value_tanh_loss: 0.1715\n",
      "Epoch 32/32\n",
      "Epoch 32/32\n",
      "999000/999000 [==============================] - 748s 749us/step - loss: 1.1821 - policy_softmax_loss: 0.9744 - value_tanh_loss: 0.1683 - val_loss: 1.1431 - val_policy_softmax_loss: 0.9379 - val_value_tanh_loss: 0.1658\n",
      "999000/999000 [==============================] - 748s 749us/step - loss: 1.1821 - policy_softmax_loss: 0.9744 - value_tanh_loss: 0.1683 - val_loss: 1.1431 - val_policy_softmax_loss: 0.9379 - val_value_tanh_loss: 0.1658\n"
     ]
    }
   ],
   "source": [
    "#sess = K.get_session()\n",
    "#sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "#K.set_session(sess)\n",
    "\n",
    "# Training\n",
    "callbacks = []\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=modelPath+\".checkpoint\", save_weights_only=False)\n",
    "callbacks.append(checkpoint)\n",
    "\n",
    "progbar = ProgbarLogger()\n",
    "callbacks.append(progbar)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='model/log2', write_grads=True, write_graph=True, write_images=True, histogram_freq=1)\n",
    "#callbacks.append(tensorboard)\n",
    "\n",
    "model.fit(x_input, [y_policy, y_value], epochs=32, batch_size=64, callbacks=callbacks, validation_split=0.001)\n",
    "\n",
    "model.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesToDotsAndBoxesImage(lines, imgWidth, imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=lines.dtype)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = lines[idx]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: 667178\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 99  0  0  0  0  0  0  0\n",
      "   0]]\n",
      "1.0\n",
      "input (11, 13): \n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 1 0 0 0 0]\n",
      " [0 1 0 1 0 1 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 1 0 0 0 1 0 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "prediction policy: \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 99  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "prediction value: \n",
      "[[-0.75]]\n",
      "target value: \n",
      "[-0.88]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABuCAIAAABk51xTAAABTElEQVR4nO3dUYrCMBRAUZXZ/5LV\nHTwHQqY3zjm/UlK85ONRY283AAAA4Hfu88evhYvna/+b+bt6/NFdMJIhQYYEGRJkSJAhQYYEGRJk\nSPi5auEP4/uClcl/37ozuyFBhgQZEmRIkCFBhgQZEmRIkCHhsil61pyE961rNyTIkCBDggwJMiTI\nkCBDggwJMiRsnKL3zZzNdVfYDQkyJMiQIEOCDAkyJMiQIEOCDAlLU/RVJ5+/78S13ZAgQ4IMCTIk\nyJAgQ4IMCTIkyJAQ/UX3rHm2eeWu7IYEGRJkSJAhQYYEGRJkSJAhQYaEI6fo2b6zzftmbLshQYYE\nGRJkSJAhQYYEGRJkSJAhofof3c9xYn2cePZ5YjckyJAgQ4IMCTIkyJAgQ4IMCTIkLL0v+kRXvePa\ns+gDyJAgQ4IMCTIkyJAgQ4IMCTIAAAAAR3kDLTgPw6S5MK4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=130x110 at 0x7F11BC674090>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.randrange(x_input.shape[0])\n",
    "print(\"example: \"+str(example))\n",
    "\n",
    "input_data = x_input[example:example+1]\n",
    "\n",
    "(prediction_lines, prediction_value) = model.predict(input_data)\n",
    "prediction_lines_print = prediction_lines * 100\n",
    "print(prediction_lines_print.astype(np.uint8))\n",
    "print(np.sum(prediction_lines))\n",
    "prediction = linesToDotsAndBoxesImage(prediction_lines[0], imgWidth, imgHeight)\n",
    "\n",
    "# print input data\n",
    "input_data_print = x_input[example,:,:,1] \n",
    "input_data_print = input_data_print.astype(np.uint8)\n",
    "print(\"input \"+str(input_data_print.shape)+\": \")\n",
    "print(input_data_print)\n",
    "\n",
    "# generate greyscale image data from input data\n",
    "planes = [1,2,3,4]\n",
    "input_imgdata = np.sum(x_input[example,:,:,1:], axis=-1) * 255\n",
    "input_imgdata = input_imgdata.astype(np.uint8)\n",
    "\n",
    "# print prediction\n",
    "prediction_data_print = prediction * 100 \n",
    "prediction_data_print = prediction_data_print.astype(np.uint8)\n",
    "print(\"prediction policy: \")\n",
    "print(prediction_data_print)\n",
    "\n",
    "print(\"prediction value: \")\n",
    "print(prediction_value)\n",
    "\n",
    "print(\"target value: \")\n",
    "print(y_value[example])\n",
    "\n",
    "# generate greyscale image data from prediction data\n",
    "prediction_imgdata = prediction * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# generate greyscale image of target data\n",
    "target_imgdata = linesToDotsAndBoxesImage(y_policy[example], imgWidth, imgHeight) * 255\n",
    "\n",
    "# merge image data in color channels\n",
    "merged_imgdata = np.stack([input_imgdata, prediction_imgdata, target_imgdata], axis=2)\n",
    "\n",
    "#create image\n",
    "img = Image.fromarray(merged_imgdata, 'RGB')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
