{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero Version 1\n",
    "\n",
    "This model is based on the model used in [Chess Alpha Zero](https://github.com/Zeta36/chess-alpha-zero). In contrast to Chess Alpha Zero, this model does not have a Dense Layer for the policy output. Also it does not yet have a value output.\n",
    "\n",
    "The architecture is modified to be fully convolutional to allow for arbitraryly sized board inputs.\n",
    "\n",
    "This model uses a custom Keras layer `LineFilterLayer` for the policy output. The `LineFilterLayer` uses a Tensorflow's `boolean_mask` method to filter out all but the lines in the output image. As a result, the policy output is a vector of all lines in the Dots and Boxes game. The training data is converted accordingly.\n",
    "\n",
    "The target images in the StageOne dataset always show exactly one line, which is the action of the Hard AI in KSquares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "modelPath = 'model/alphaZeroV1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(K.image_data_format()) \n",
    "# expected output: channels_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotsAndBoxesToCategorical(inputData):\n",
    "    inp = np.copy(inputData)\n",
    "    inp[inp == 255] = 1 # Line - comes first so that target data only has two categories\n",
    "    inp[inp == 65] = 2 # Box A\n",
    "    inp[inp == 150] = 3 # Box B\n",
    "    inp[inp == 215] = 4 # Dot\n",
    "    cat = to_categorical(inp)\n",
    "    newShape = inp.shape + (cat.shape[-1],)\n",
    "    return cat.reshape(newShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0   0   0 255   0   0   0   0   0 255   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0 255   0   0   0   0   0 255   0   0   0]\n",
      " [  0 215   0 215   0 215 255 215 255 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0 255   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215 255 215   0]\n",
      " [  0 255   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215 255 215 255 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 255   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "(1000000, 11, 13)\n",
      "(1000000, 11, 13)\n",
      "\n",
      "normalized data:\n",
      "[[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "  [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "  [1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "  [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
      "  [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "  [1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "[[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "(1000000, 11, 13, 5)\n",
      "(1000000, 11, 13, 2)\n"
     ]
    }
   ],
   "source": [
    "rawDataset = np.load('stageOne5x4.npz')\n",
    "x_train = rawDataset['x_train']\n",
    "y_train = rawDataset['y_train']\n",
    "x_train_cat = dotsAndBoxesToCategorical(x_train)\n",
    "y_train_cat = dotsAndBoxesToCategorical(y_train)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"original data:\")\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\nnormalized data:\")\n",
    "print(np.transpose(x_train_cat[0]))\n",
    "print(np.transpose(y_train_cat[0]))\n",
    "print(x_train_cat.shape)\n",
    "print(y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False,  True, False,  True, False,  True, False,  True, False,\n",
       "         True, False,  True, False],\n",
       "       [False, False,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def imgSizeToBoxes(x):\n",
    "    return (x-3)/2\n",
    "\n",
    "def lineFilterMatrixNP(imgWidth,imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=np.bool)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = 1\n",
    "    return mat\n",
    "\n",
    "lineFilterMatrixNP(13,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 49)\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "y_train_lines = y_train[:,lineFilterMatrixNP(y_train.shape[-1], y_train.shape[-2])]\n",
    "print(y_train_lines.shape)\n",
    "print(y_train_lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LineFilterLayer\n",
    "\n",
    "This layer takes n_samples of Dots and Boxes images and returns\n",
    "only the line pixels in a flattened list\n",
    "```\n",
    "input: (n_samples, img_height, img_width)\n",
    "output: (n_samples, lines_cnt)\n",
    "\n",
    "box_width = (img_width-3)/2\n",
    "box_height = (img_height-3)/2\n",
    "lines_cnt = 2 * box_width * box_height + box_width + box_height\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This layer takes n_samples of Dots and Boxes images and returns\n",
    "only the line pixels in a flattened list\n",
    "input: (n_samples, img_height, img_width)\n",
    "output: (n_samples, 2*((w-3)/2)*((h-3)/2) + ((w-3)/2) + ((h-3)/2)) \n",
    "where w is img_width and h is img_height\n",
    "'''\n",
    "class LineFilterLayer(Layer):\n",
    "    def __init__(self, imgWidth, imgHeight, **kwargs):\n",
    "        self.filterMatrix = self.lineFilterMatrix(imgWidth, imgHeight)\n",
    "        print(self.filterMatrix)\n",
    "        w = imgWidth\n",
    "        h = imgHeight\n",
    "        self.output_dim = 2*((w-3)/2)*((h-3)/2) + ((w-3)/2) + ((h-3)/2) \n",
    "        super(LineFilterLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        shape = list(input_shape)\n",
    "        print(input_shape)\n",
    "        assert len(shape) == 4\n",
    "        assert shape[3] == 1\n",
    "        self.compute_output_shape(input_shape)\n",
    "        super(LineFilterLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        assert self.filterMatrix is not None\n",
    "        assert self.output_dim is not None\n",
    "        assert self.output_dim > 0\n",
    "        lines2D = tf.boolean_mask(x, self.filterMatrix, name='lineFilter', axis=1)\n",
    "        shape = K.shape(lines2D)\n",
    "        #print(shape)\n",
    "        #print(shape[0])\n",
    "        return tf.reshape(lines2D, (shape[0], self.output_dim))\n",
    "        return lines2D\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        w = input_shape[-2]\n",
    "        h = input_shape[-3]\n",
    "        if w is None or h is None:\n",
    "            return (input_shape[0], None)\n",
    "        self.filterMatrix = self.lineFilterMatrix(w,h)\n",
    "        wbox = self.imgSizeToBoxes(w)\n",
    "        hbox = self.imgSizeToBoxes(h)\n",
    "        self.output_dim = 2 * wbox * hbox + wbox + hbox\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "    \n",
    "    def imgSizeToBoxes(self, x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        return (x-3)/2\n",
    "\n",
    "    def lineFilterMatrix(self, imgWidth,imgHeight):\n",
    "        boxWidth = imgSizeToBoxes(imgWidth)\n",
    "        boxHeight = imgSizeToBoxes(imgHeight)\n",
    "        linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "        mat = np.zeros((imgHeight, imgWidth), dtype=np.bool)\n",
    "        for idx in range(linesCnt):\n",
    "            y1 = idx / ((2*boxWidth) + 1)\n",
    "            if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "                # horizontal line\n",
    "                x1 = idx % ((2*boxWidth) + 1)\n",
    "                x2 = x1 + 1\n",
    "                y2 = y1\n",
    "            else:\n",
    "                # vertical line\n",
    "                x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "                x2 = x1\n",
    "                y2 = y1 + 1\n",
    "            px = x2 * 2 + y2 - y1\n",
    "            py = y2 * 2 + x2 - x1\n",
    "            mat[py,px] = 1\n",
    "        return tf.convert_to_tensor(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(11, 13), dtype=bool)\n",
      "(None, None, None, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 5 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_conv (Conv2D)             (None, None, None, 6 8064        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_relu (Activation)         (None, None, None, 6 0           input_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 256         input_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res1_conv1_64 (Conv2D)          (None, None, None, 6 102464      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res1_batchnorm1 (BatchNormaliza (None, None, None, 6 256         res1_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1_relu1 (Activation)         (None, None, None, 6 0           res1_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res1_conv2-64 (Conv2D)          (None, None, None, 6 102464      res1_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res1_batchnorm2 (BatchNormaliza (None, None, None, 6 256         res1_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1_add (Add)                  (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "                                                                 res1_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res1_relu2 (Activation)         (None, None, None, 6 0           res1_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res2_conv1_64 (Conv2D)          (None, None, None, 6 102464      res1_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2_batchnorm1 (BatchNormaliza (None, None, None, 6 256         res2_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2_relu1 (Activation)         (None, None, None, 6 0           res2_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2_conv2-64 (Conv2D)          (None, None, None, 6 102464      res2_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2_batchnorm2 (BatchNormaliza (None, None, None, 6 256         res2_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2_add (Add)                  (None, None, None, 6 0           res1_relu2[0][0]                 \n",
      "                                                                 res2_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2_relu2 (Activation)         (None, None, None, 6 0           res2_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res3_conv1_64 (Conv2D)          (None, None, None, 6 102464      res2_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3_batchnorm1 (BatchNormaliza (None, None, None, 6 256         res3_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3_relu1 (Activation)         (None, None, None, 6 0           res3_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_conv2-64 (Conv2D)          (None, None, None, 6 102464      res3_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3_batchnorm2 (BatchNormaliza (None, None, None, 6 256         res3_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3_add (Add)                  (None, None, None, 6 0           res2_relu2[0][0]                 \n",
      "                                                                 res3_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_relu2 (Activation)         (None, None, None, 6 0           res3_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res4_conv1_64 (Conv2D)          (None, None, None, 6 102464      res3_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4_batchnorm1 (BatchNormaliza (None, None, None, 6 256         res4_conv1_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4_relu1 (Activation)         (None, None, None, 6 0           res4_batchnorm1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4_conv2-64 (Conv2D)          (None, None, None, 6 102464      res4_relu1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4_batchnorm2 (BatchNormaliza (None, None, None, 6 256         res4_conv2-64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4_add (Add)                  (None, None, None, 6 0           res3_relu2[0][0]                 \n",
      "                                                                 res4_batchnorm2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4_relu2 (Activation)         (None, None, None, 6 0           res4_add[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_conv (Conv2D)            (None, None, None, 1 1601        res4_relu2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "line_filter_layer_2 (LineFilter (None, None)         0           output_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_softmax (Activation)     (None, None)         0           line_filter_layer_2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 831,681\n",
      "Trainable params: 830,529\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernelSize = (5,5)\n",
    "filterCnt = 64\n",
    "l2reg = 1e-4\n",
    "resBlockCnt = 4\n",
    "\n",
    "def build_residual_block(x, index):\n",
    "        in_x = x\n",
    "        res_name = \"res\"+str(index)\n",
    "        x = Conv2D(filters=filterCnt, kernel_size=kernelSize, padding=\"same\",\n",
    "                   data_format=\"channels_last\", kernel_regularizer=l2(l2reg), \n",
    "                   name=res_name+\"_conv1_\"+str(filterCnt))(x)\n",
    "        x = BatchNormalization(name=res_name+\"_batchnorm1\")(x)\n",
    "        x = Activation(\"relu\",name=res_name+\"_relu1\")(x)\n",
    "        x = Conv2D(filters=filterCnt, kernel_size=kernelSize, padding=\"same\",\n",
    "                   data_format=\"channels_last\", kernel_regularizer=l2(l2reg), \n",
    "                   name=res_name+\"_conv2-\"+str(filterCnt))(x)\n",
    "        x = BatchNormalization(name=\"res\"+str(index)+\"_batchnorm2\")(x)\n",
    "        x = Add(name=res_name+\"_add\")([in_x, x])\n",
    "        x = Activation(\"relu\", name=res_name+\"_relu2\")(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "img_input = Input(shape=(None,None,5,))\n",
    "x = Conv2D(filterCnt, kernelSize, padding='same', kernel_regularizer=l2(l2reg), name=\"input_conv\")(img_input)\n",
    "x = Activation(\"relu\", name=\"input_relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "for i in range(resBlockCnt):\n",
    "    x = build_residual_block(x, i+1)\n",
    "\n",
    "res_out = x\n",
    "\n",
    "x = Conv2D(1, kernelSize, padding='same', kernel_regularizer=l2(l2reg), name=\"output_conv\")(x)\n",
    "x = LineFilterLayer(y_train.shape[-1], y_train.shape[-2])(x)\n",
    "x = Activation(\"softmax\", name=\"output_softmax\")(x)\n",
    "    \n",
    "model = Model(inputs=img_input, outputs=x)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 999000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "179904/999000 [====>.........................] - ETA: 29:46 - loss: 664.4174"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-26faf630d5a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sess = K.get_session()\n",
    "#sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "#K.set_session(sess)\n",
    "\n",
    "# Training\n",
    "callbacks = []\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='model/AlphaZeroV1-checkpoint.h5', save_weights_only=False)\n",
    "callbacks.append(checkpoint)\n",
    "\n",
    "progbar = ProgbarLogger()\n",
    "callbacks.append(progbar)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='model/log2', write_grads=True, write_graph=True, write_images=True, histogram_freq=1)\n",
    "callbacks.append(tensorboard)\n",
    "\n",
    "model.fit(x_train_cat, y_train_lines, epochs=5, batch_size=64, callbacks=callbacks, validation_split=0.001)\n",
    "\n",
    "model.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesToDotsAndBoxesImage(lines, imgWidth, imgHeight):\n",
    "    boxWidth = imgSizeToBoxes(imgWidth)\n",
    "    boxHeight = imgSizeToBoxes(imgHeight)\n",
    "    linesCnt = 2*boxWidth*boxHeight+boxWidth+boxHeight\n",
    "    mat = np.zeros((imgHeight, imgWidth), dtype=lines.dtype)\n",
    "    for idx in range(linesCnt):\n",
    "        y1 = idx / ((2*boxWidth) + 1)\n",
    "        if idx % ((2*boxWidth) + 1) < boxWidth:\n",
    "            # horizontal line\n",
    "            x1 = idx % ((2*boxWidth) + 1)\n",
    "            x2 = x1 + 1\n",
    "            y2 = y1\n",
    "        else:\n",
    "            # vertical line\n",
    "            x1 = idx % ((2*boxWidth) + 1) - boxWidth\n",
    "            x2 = x1\n",
    "            y2 = y1 + 1\n",
    "        px = x2 * 2 + y2 - y1\n",
    "        py = y2 * 2 + x2 - x1\n",
    "        mat[py,px] = lines[idx]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: 829790\n",
      "[[3 0 3 0 0 3 3 3 3 3 2 0 3 3 3 3 3 3 3 3 3 3 3 3 2 0 3 3 0 3 0 0 3 3 0 0\n",
      "  0 0 3 0 0 0 3 3 0 0 0 3 0]]\n",
      "1.0\n",
      "input (11, 13): \n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215 255 215   0 215 255 215 255 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215 255 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0 255   0   0   0 255   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215 255 215 255 215   0]\n",
      " [  0   0   0   0   0 255   0   0   0   0   0   0   0]\n",
      " [  0 215 255 215 255 215 255 215   0 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "prediction: \n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 3 0 0 0 0 0 0]\n",
      " [0 3 0 3 0 3 0 3 0 3 0 2 0]\n",
      " [0 0 0 0 3 0 3 0 3 0 3 0 0]\n",
      " [0 3 0 3 0 3 0 3 0 3 0 3 0]\n",
      " [0 0 3 0 3 0 2 0 0 0 3 0 0]\n",
      " [0 3 0 0 0 3 0 0 0 0 0 3 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 3 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABuCAIAAABk51xTAAABjElEQVR4nO3dwU3DQBBAUYOQgE5I\n/8UknQAn0sEEaRXyV7x3HTkGffmwDIbjAAAAAH7naR6fx+npbbz2a5p+jJ98Sd536Wsep8/jlD8i\nQ4IMCTIkyJAgQ4IMCTIkyJBw4xR9jOfVYzyv/rtrX8fp9zT0NCTIkCBDggwJMiTIkCBDggwJMiQs\n7aIftU/e8tpp6GlokCFBhgQZEmRIkCFBhgQZEmRIqO6iF/a6O+6xPQ0JMiTIkCBDggwJMiTIkCBD\nggwJD3sveuna8Yx9Hs/Y8074jt/v+MmehgQZEmRIkCFBhgQZEmRIkCFBhoQ77qJ/Vm78Pk4/73bf\nFXbRu5MhQYYEGRJkSJAhQYYEGRJkSHiZxys74cv8e9fzfcdz8rzXnd/Hns/YS3+j2y56dzIkyJAg\nQ4IMCTIkyJAgQ4IMCbdWsws74RU77pPtorcnQ4IMCTIkyJAgQ4IMCTIkyJBwaxc9npMf9b+XV/bJ\np/HnAis7cO9Fb0+GBBkSZEiQIUGGBBkSZEiQAQAAANjKFerkRg8+9pG6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=130x110 at 0x7FD764628F10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.randrange(x_train.shape[0])\n",
    "print(\"example: \"+str(example))\n",
    "\n",
    "input_data = x_train[example:example+1]\n",
    "input_data_cat = x_train_cat[example:example+1]\n",
    "\n",
    "prediction_lines = model.predict(input_data_cat)\n",
    "prediction_lines_print = prediction_lines * 100\n",
    "print(prediction_lines_print.astype(np.uint8))\n",
    "print(np.sum(prediction_lines))\n",
    "prediction = linesToDotsAndBoxesImage(prediction_lines[0], x_train.shape[2], x_train.shape[1])\n",
    "\n",
    "# print input data\n",
    "input_data_print = x_train[example,:,:] \n",
    "input_data_print = input_data_print.astype(np.uint8)\n",
    "print(\"input \"+str(input_data_print.shape)+\": \")\n",
    "print(input_data_print)\n",
    "\n",
    "# generate greyscale image data from input data\n",
    "target_imgdata = x_train[example,:,:] \n",
    "target_imgdata = target_imgdata.astype(np.uint8)\n",
    "\n",
    "# print prediction\n",
    "prediction_data_print = prediction * 100 \n",
    "prediction_data_print = prediction_data_print.astype(np.uint8)\n",
    "print(\"prediction: \")\n",
    "print(prediction_data_print)\n",
    "\n",
    "# generate greyscale image data from prediction data\n",
    "prediction_imgdata = prediction * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# merge image data in color channels\n",
    "tmp = np.zeros((prediction.shape[0], prediction.shape[1]), dtype=np.uint8)\n",
    "merged_imgdata = np.stack([target_imgdata, prediction_imgdata, tmp], axis=2)\n",
    "\n",
    "#create image\n",
    "img = Image.fromarray(merged_imgdata, 'RGB')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
