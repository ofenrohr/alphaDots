{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "print(K.image_data_format()) \n",
    "# expected output: channels_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model/train-checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0 255   0 255   0 255   0   0   0   0   0]\n",
      " [  0 215 255 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0 255   0   0   0 255   0]\n",
      " [  0 215   0 215 255 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255   0   0   0]\n",
      " [  0 215   0 215   0 215   0 215 255 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 215 255 215   0 215   0 215   0 215   0 215   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 255   0 255   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255   0 255   0]\n",
      " [  0   0   0   0   0   0   0   0 255   0 255   0   0]\n",
      " [  0 255   0 255   0 255   0   0   0 255   0   0   0]\n",
      " [  0   0 255   0   0   0 255   0   0   0 255   0   0]\n",
      " [  0 255   0 255   0 255   0   0   0   0   0 255   0]\n",
      " [  0   0 255   0 255   0 255   0   0   0 255   0   0]\n",
      " [  0 255   0 255   0 255   0 255   0 255   0 255   0]\n",
      " [  0   0   0   0 255   0 255   0 255   0 255   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "(100000, 11, 13)\n",
      "(100000, 11, 13)\n",
      "\n",
      "normalized data:\n",
      "[[[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  0.    0.84  0.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    1.    0.    0.    0.    0.    0.    1.    0.  ]\n",
      "  [ 0.    0.84  1.    0.84  0.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  1.    0.84  0.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  1.    0.84  1.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  0.    0.84  0.    0.84  1.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.84  0.    0.84  1.    0.84  0.    0.84  0.    0.84  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]]\n",
      "[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "  [ 0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.]\n",
      "  [ 0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]\n",
      "(100000, 11, 13, 1)\n",
      "(100000, 11, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "firstTryDataset = np.load('basicStrategy5x4.npz')\n",
    "x_train = firstTryDataset['x_train']\n",
    "y_train = firstTryDataset['y_train']\n",
    "\n",
    "print(\"original data:\")\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "print(\"\\nnormalized data:\")\n",
    "sp = x_train.shape\n",
    "x_train = x_train.reshape((sp[0],sp[1],sp[2],1))\n",
    "sp = y_train.shape\n",
    "y_train = y_train.reshape((sp[0],sp[1],sp[2],1))\n",
    "\n",
    "x_train = x_train.astype(K.floatx())\n",
    "y_train = y_train.astype(K.floatx())\n",
    "#x_train = np.true_divide(x_train,255.0)\n",
    "x_train /= 255\n",
    "y_train /= 255\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.transpose(x_train[0]))\n",
    "print(np.transpose(y_train[0]))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 11, 13, 2)\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.]\n",
      " [ 1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.]\n",
      " [ 1.  1.  0.  1.  1.  1.  0.  1.  1.  1.  0.  1.  1.]\n",
      " [ 1.  0.  1.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  1.  1.]\n",
      " [ 1.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.]\n",
      " [ 1.  1.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "y_cat = to_categorical(y_train).reshape(y_train.shape[0], y_train.shape[1], y_train.shape[2], 2)\n",
    "print(y_cat.shape)\n",
    "print(y_cat[0,:,:,0])\n",
    "print(y_cat[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  84 100  84 100  84 100  84 100  84 100  84   0]\n",
      " [  0 100  25 100   0   0   0   0   0 100  25 100   0]\n",
      " [  0  84 100  84   0  84 100  84   0  84 100  84   0]\n",
      " [  0 100  25 100   0 100  25 100   0 100  58 100   0]\n",
      " [  0  84 100  84 100  84 100  84   0  84 100  84   0]\n",
      " [  0 100  25 100  25 100  25 100   0 100  58 100   0]\n",
      " [  0  84 100  84 100  84 100  84   0  84 100  84   0]\n",
      " [  0 100  58 100  58 100   0   0   0 100  25 100   0]\n",
      " [  0  84 100  84 100  84   0  84 100  84 100  84   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "prediction: \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 96  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABuCAIAAABk51xTAAABeUlEQVR4nO3cvU3DYBRAUfNTMghZ\ng22YiG1YIxmEFkFLwwPJMr4m57RPlmNdufj0FC8LAAAA8Ds38/g8Th/H6cW1X5zG6e045Y/IkCBD\nggwJMiTIkCBDggwJMiT8cIr+GKdP4/R1zY3n8fyzVtjreb0NCTIkyJAgQ4IMCTIkyJAgQ4IMCffz\neN6vzufG+drlbRqeH6bpdjvhDZ935G1IkCFBhgQZEmRIkCFBhgQZEmRIiO6im/d9GafPK+7rbUiQ\nIUGGBBkSZEiQIUGGBBkSZEjYbRc9n1c33AmPx9nL+LPmc7Jd9OHJkCBDggwJMiTIkCBDggwJMiTs\ntove61q7aL4lQ4IMCTIkyJAgQ4IMCTIkyJBwdd/onv8Xvd3z+kb3AciQIEOCDAkyJMiQIEOCDAky\nJKzaRa/ZzW63113DN7qvmgwJMiTIkCBDggwJMiTIkCBDwiF30ae7aXp+3+q+dtH/nAwJMiTIkCBD\nggwJMiTIkCADAAAAcCif74s6gudAvcEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=130x110 at 0x7F686BDF76D0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.randrange(x_train.shape[0])\n",
    "\n",
    "input_data = np.array([x_train[example]])\n",
    "\n",
    "\n",
    "prediction = model.predict(input_data)\n",
    "\n",
    "# print input data\n",
    "input_data_print = x_train[example,:,:,0] * 100\n",
    "input_data_print = input_data_print.astype(np.uint8)\n",
    "print(\"input: \")\n",
    "print(input_data_print)\n",
    "\n",
    "# generate greyscale image data from input data\n",
    "target_imgdata = x_train[example,:,:,0] * 255\n",
    "target_imgdata = target_imgdata.astype(np.uint8)\n",
    "\n",
    "# print prediction\n",
    "prediction_data_print = prediction[0,:,:,1] * 100 \n",
    "prediction_data_print = prediction_data_print.astype(np.uint8)\n",
    "print(\"prediction: \")\n",
    "print(prediction_data_print)\n",
    "\n",
    "# generate greyscale image data from prediction data\n",
    "prediction_imgdata = prediction[0] * 255\n",
    "prediction_imgdata = prediction_imgdata.astype(np.uint8)\n",
    "\n",
    "# merge image data in color channels\n",
    "tmp = np.zeros((prediction[0].shape[0], prediction[0].shape[1]), dtype=np.uint8)\n",
    "merged_imgdata = np.stack([target_imgdata, prediction_imgdata[:,:,1], tmp], axis=2)\n",
    "\n",
    "#create image\n",
    "img = Image.fromarray(merged_imgdata, 'RGB')\n",
    "img = img.resize(size=(img.size[0]*10, img.size[1]*10))\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
